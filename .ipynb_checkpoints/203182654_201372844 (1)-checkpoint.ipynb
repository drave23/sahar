{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYL2yhps-MoR"
   },
   "source": [
    "<h1> ~Neural Collaborative Filtering -  Implementation with Keras </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 2668,
     "status": "ok",
     "timestamp": 1532807980180,
     "user": {
      "displayName": "Ran Tsur",
      "photoUrl": "//lh3.googleusercontent.com/-pkQ4mq31yyM/AAAAAAAAAAI/AAAAAAAAABg/OJrKb1aE-5Q/s50-c-k-no/photo.jpg",
      "userId": "106754954225433138332"
     },
     "user_tz": -180
    },
    "id": "Qar2rpog-MoS",
    "outputId": "1b22139b-f649-45f1-cb03-4d16657f3bf7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as T\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Sequential, Model, load_model, save_model\n",
    "from keras.layers.core import Dense, Lambda, Activation\n",
    "from keras.layers import Embedding, Input, Dense, merge, Reshape, Merge, Flatten, Dropout\n",
    "from keras.optimizers import Adagrad, Adam, SGD, RMSprop, Adamax\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Multiply, Concatenate\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from time import time\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import math\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "DSMWU4zdDgvX"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive ## you will have install for every colab session\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from google.colab import files\n",
    "\n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UqaKXWj2-MoX"
   },
   "source": [
    "**Define dataset folder and files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ATWd9BvF-MoX"
   },
   "outputs": [],
   "source": [
    "RATING_DATA_FILE_TRAIN = 'u1.base'\n",
    "RATING_DATA_FILE_TEST = 'u1.test'\n",
    "MOVIES_DATA_FILE_PATH = 'u.item'\n",
    "USERS_DATA_FILE_PATH = 'u.user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "jYlcT_ptB7Wu"
   },
   "outputs": [],
   "source": [
    "rating_file_import_train = drive.CreateFile({'id':'1_UmoSVT7fEwYBvDBGWSzAeekdQEOJBy6'})\n",
    "rating_file_import_train.GetContentFile(RATING_DATA_FILE_TRAIN)\n",
    "\n",
    "rating_file_import_test = drive.CreateFile({'id':'17DIYedqGvQO7SYgnfdPYYIW2ycRMyTWW'})\n",
    "rating_file_import_test.GetContentFile(RATING_DATA_FILE_TEST)\n",
    "\n",
    "movies_file_import = drive.CreateFile({'id':'1b3gelAzp7gPoFZSHEBHd7jSdiE1op_4j'})\n",
    "movies_file_import.GetContentFile(MOVIES_DATA_FILE_PATH)\n",
    "\n",
    "users_file_import = drive.CreateFile({'id':'1k0QZ9mw2OA0bLCLj0mt180Vs6Yyid8of'})\n",
    "users_file_import.GetContentFile(USERS_DATA_FILE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZsHirou-Mob"
   },
   "source": [
    "**The user and item id for embedding should start from 0. Update ids and save to file **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "WLCe3LSG-Mob"
   },
   "outputs": [],
   "source": [
    "r_cols = ['userid', 'movieid', 'rating', 'timestamp']\n",
    "ratings_train_df = pd.read_csv(RATING_DATA_FILE_TRAIN, sep='\\t', engine='python', encoding='latin-1',names=r_cols)\n",
    "ratings_train_df['user_emb_id'] = ratings_train_df['userid'] - 1\n",
    "ratings_train_df['movie_emb_id'] = ratings_train_df['movieid'] - 1\n",
    "\n",
    "ratings_test_df = pd.read_csv(RATING_DATA_FILE_TEST, sep='\\t', engine='python', encoding='latin-1',names=r_cols)\n",
    "ratings_test_df['user_emb_id'] = ratings_test_df['userid'] - 1\n",
    "ratings_test_df['movie_emb_id'] = ratings_test_df['movieid'] - 1\n",
    "\n",
    "u_cols = ['userid','age','gender','profession', '']\n",
    "users = pd.read_csv(USERS_DATA_FILE_PATH, sep='|', engine='python', encoding='latin-1',names=u_cols)\n",
    "users['gender'] = users['gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "i_cols = ['movieid', 'title']\n",
    "items_df = pd.read_csv(MOVIES_DATA_FILE_PATH, sep='|', engine='python', encoding='latin-1', names=i_cols, usecols=[0, 1])\n",
    "\n",
    "train_df = pd.merge(items_df, ratings_train_df, on='movieid')\n",
    "test_df = pd.merge(items_df, ratings_test_df, on='movieid')\n",
    "joined_df = pd.concat([train_df, test_df])\n",
    "\n",
    "Users = joined_df['user_emb_id'].values\n",
    "Movies = joined_df['movie_emb_id'].values\n",
    "Ratings = joined_df['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1532808041643,
     "user": {
      "displayName": "Ran Tsur",
      "photoUrl": "//lh3.googleusercontent.com/-pkQ4mq31yyM/AAAAAAAAAAI/AAAAAAAAABg/OJrKb1aE-5Q/s50-c-k-no/photo.jpg",
      "userId": "106754954225433138332"
     },
     "user_tz": -180
    },
    "id": "WFqnpH0gt3B2",
    "outputId": "9ae2e091-9dc6-4b45-d3c3-fe32b69b40dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max user id: 943    Max movie id: 1682\n"
     ]
    }
   ],
   "source": [
    "max_userid = joined_df['userid'].drop_duplicates().max()\n",
    "max_movieid = joined_df['movieid'].drop_duplicates().max()\n",
    "print(\"Max user id:\", max_userid, \"   Max movie id:\", max_movieid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EXS_qwtCHTYV"
   },
   "source": [
    "## Ex 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9c21Uuhz-Mou"
   },
   "source": [
    "**Define matrix factorization model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "OZbAaKcq-Mou"
   },
   "outputs": [],
   "source": [
    "def get_model(num_users, num_items, latent_dim):\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "\n",
    "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding', input_length=1)\n",
    "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding', input_length=1)   \n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(MF_Embedding_User(user_input))\n",
    "    item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
    "    \n",
    "    # Element-wise product of user and item embeddings\n",
    "    prediction = merge([user_latent, item_latent], mode = 'dot')\n",
    "    \n",
    "    \n",
    "    model = Model(input=[user_input, item_input], output=prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8SECj2K-Mo3"
   },
   "source": [
    "**Define embedding size and compile model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1532808049353,
     "user": {
      "displayName": "Ran Tsur",
      "photoUrl": "//lh3.googleusercontent.com/-pkQ4mq31yyM/AAAAAAAAAAI/AAAAAAAAABg/OJrKb1aE-5Q/s50-c-k-no/photo.jpg",
      "userId": "106754954225433138332"
     },
     "user_tz": -180
    },
    "id": "pHMeRWAa1oRm",
    "outputId": "46cc2588-82be-436d-b4b3-fb26202f0923"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"me...)`\n"
     ]
    }
   ],
   "source": [
    "K_LATENT = 20\n",
    "MF_model = get_model(max_userid,max_movieid,K_LATENT)\n",
    "MF_model.compile(loss='mse', optimizer='adamax',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0i_p3hpsh5BL"
   },
   "source": [
    "**Train model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2638
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 312151,
     "status": "ok",
     "timestamp": 1532808366182,
     "user": {
      "displayName": "Ran Tsur",
      "photoUrl": "//lh3.googleusercontent.com/-pkQ4mq31yyM/AAAAAAAAAAI/AAAAAAAAABg/OJrKb1aE-5Q/s50-c-k-no/photo.jpg",
      "userId": "106754954225433138332"
     },
     "user_tz": -180
    },
    "id": "gNhPAmChHz18",
    "outputId": "7d9b38ad-4e49-44f4-9365-6966224931e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/80\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 13.6511 - mean_absolute_error: 3.5216 - val_loss: 13.6325 - val_mean_absolute_error: 3.5086\n",
      "Epoch 2/80\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 12.3171 - mean_absolute_error: 3.3285 - val_loss: 11.4834 - val_mean_absolute_error: 3.1933\n",
      "Epoch 3/80\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 8.4811 - mean_absolute_error: 2.6555 - val_loss: 7.6802 - val_mean_absolute_error: 2.4921\n",
      "Epoch 4/80\n",
      "37952/80000 [=============>................] - ETA: 1s - loss: 5.6958 - mean_absolute_error: 2.051480000/80000 [==============================] - 4s 52us/step - loss: 5.1173 - mean_absolute_error: 1.9107 - val_loss: 5.0138 - val_mean_absolute_error: 1.8835\n",
      "Epoch 5/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 3.4848 - mean_absolute_error: 1.4997 - val_loss: 3.6386 - val_mean_absolute_error: 1.5364\n",
      "Epoch 6/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 2.6117 - mean_absolute_error: 1.2612 - val_loss: 2.8492 - val_mean_absolute_error: 1.3235\n",
      "Epoch 7/80\n",
      "77024/80000 [===========================>..] - ETA: 0s - loss: 2.0973 - mean_absolute_error: 1.113680000/80000 [==============================] - 4s 51us/step - loss: 2.0910 - mean_absolute_error: 1.1119 - val_loss: 2.3512 - val_mean_absolute_error: 1.1841\n",
      "Epoch 8/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 1.7586 - mean_absolute_error: 1.0133 - val_loss: 2.0139 - val_mean_absolute_error: 1.0864\n",
      "Epoch 9/80\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 1.5346 - mean_absolute_error: 0.9443 - val_loss: 1.7772 - val_mean_absolute_error: 1.0153\n",
      "Epoch 10/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 1.3795 - mean_absolute_error: 0.8950 - val_loss: 1.6069 - val_mean_absolute_error: 0.9631\n",
      "Epoch 11/80\n",
      " 2240/80000 [..............................] - ETA: 3s - loss: 1.2985 - mean_absolute_error: 0.864580000/80000 [==============================] - 4s 52us/step - loss: 1.2688 - mean_absolute_error: 0.8592 - val_loss: 1.4791 - val_mean_absolute_error: 0.9236\n",
      "Epoch 12/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 1.1876 - mean_absolute_error: 0.8325 - val_loss: 1.3830 - val_mean_absolute_error: 0.8937\n",
      "Epoch 13/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 1.1269 - mean_absolute_error: 0.8125 - val_loss: 1.3075 - val_mean_absolute_error: 0.8709\n",
      "Epoch 14/80\n",
      "72288/80000 [==========================>...] - ETA: 0s - loss: 1.0845 - mean_absolute_error: 0.798280000/80000 [==============================] - 4s 51us/step - loss: 1.0796 - mean_absolute_error: 0.7966 - val_loss: 1.2483 - val_mean_absolute_error: 0.8526\n",
      "Epoch 15/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 1.0425 - mean_absolute_error: 0.7847 - val_loss: 1.2001 - val_mean_absolute_error: 0.8371\n",
      "Epoch 16/80\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 1.0127 - mean_absolute_error: 0.7747 - val_loss: 1.1606 - val_mean_absolute_error: 0.8249\n",
      "Epoch 17/80\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.9883 - mean_absolute_error: 0.7665 - val_loss: 1.1290 - val_mean_absolute_error: 0.8150\n",
      "Epoch 18/80\n",
      " 2304/80000 [..............................] - ETA: 3s - loss: 0.9369 - mean_absolute_error: 0.735680000/80000 [==============================] - 4s 51us/step - loss: 0.9680 - mean_absolute_error: 0.7597 - val_loss: 1.1025 - val_mean_absolute_error: 0.8065\n",
      "Epoch 19/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.9506 - mean_absolute_error: 0.7537 - val_loss: 1.0803 - val_mean_absolute_error: 0.7992\n",
      "Epoch 20/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.9360 - mean_absolute_error: 0.7488 - val_loss: 1.0610 - val_mean_absolute_error: 0.7931\n",
      "Epoch 21/80\n",
      "72256/80000 [==========================>...] - ETA: 0s - loss: 0.9247 - mean_absolute_error: 0.744580000/80000 [==============================] - 4s 51us/step - loss: 0.9227 - mean_absolute_error: 0.7440 - val_loss: 1.0435 - val_mean_absolute_error: 0.7878\n",
      "Epoch 22/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.9110 - mean_absolute_error: 0.7401 - val_loss: 1.0284 - val_mean_absolute_error: 0.7820\n",
      "Epoch 23/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.9009 - mean_absolute_error: 0.7360 - val_loss: 1.0168 - val_mean_absolute_error: 0.7790\n",
      "Epoch 24/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.8914 - mean_absolute_error: 0.7329 - val_loss: 1.0053 - val_mean_absolute_error: 0.7750\n",
      "Epoch 25/80\n",
      " 2208/80000 [..............................] - ETA: 3s - loss: 0.8704 - mean_absolute_error: 0.732480000/80000 [==============================] - 4s 51us/step - loss: 0.8831 - mean_absolute_error: 0.7294 - val_loss: 0.9966 - val_mean_absolute_error: 0.7717\n",
      "Epoch 26/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.8753 - mean_absolute_error: 0.7265 - val_loss: 0.9873 - val_mean_absolute_error: 0.7686\n",
      "Epoch 27/80\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 0.8678 - mean_absolute_error: 0.7236 - val_loss: 0.9802 - val_mean_absolute_error: 0.7666\n",
      "Epoch 28/80\n",
      "70976/80000 [=========================>....] - ETA: 0s - loss: 0.8607 - mean_absolute_error: 0.720680000/80000 [==============================] - 4s 51us/step - loss: 0.8611 - mean_absolute_error: 0.7213 - val_loss: 0.9738 - val_mean_absolute_error: 0.7642\n",
      "Epoch 29/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.8548 - mean_absolute_error: 0.7187 - val_loss: 0.9672 - val_mean_absolute_error: 0.7619\n",
      "Epoch 30/80\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.8484 - mean_absolute_error: 0.7162 - val_loss: 0.9622 - val_mean_absolute_error: 0.7600\n",
      "Epoch 31/80\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.8425 - mean_absolute_error: 0.7139 - val_loss: 0.9574 - val_mean_absolute_error: 0.7579\n",
      "Epoch 32/80\n",
      " 2176/80000 [..............................] - ETA: 3s - loss: 0.8070 - mean_absolute_error: 0.705680000/80000 [==============================] - 4s 50us/step - loss: 0.8372 - mean_absolute_error: 0.7114 - val_loss: 0.9519 - val_mean_absolute_error: 0.7563\n",
      "Epoch 33/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.8317 - mean_absolute_error: 0.7093 - val_loss: 0.9479 - val_mean_absolute_error: 0.7547\n",
      "Epoch 34/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.8263 - mean_absolute_error: 0.7070 - val_loss: 0.9436 - val_mean_absolute_error: 0.7532\n",
      "Epoch 35/80\n",
      "67776/80000 [========================>.....] - ETA: 0s - loss: 0.8212 - mean_absolute_error: 0.705580000/80000 [==============================] - 4s 54us/step - loss: 0.8217 - mean_absolute_error: 0.7049 - val_loss: 0.9402 - val_mean_absolute_error: 0.7523\n",
      "Epoch 36/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.8165 - mean_absolute_error: 0.7027 - val_loss: 0.9364 - val_mean_absolute_error: 0.7505\n",
      "Epoch 37/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.8119 - mean_absolute_error: 0.7005 - val_loss: 0.9333 - val_mean_absolute_error: 0.7493\n",
      "Epoch 38/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.8068 - mean_absolute_error: 0.6983 - val_loss: 0.9299 - val_mean_absolute_error: 0.7479\n",
      "Epoch 39/80\n",
      "   32/80000 [..............................] - ETA: 14s - loss: 0.6069 - mean_absolute_error: 0.638380000/80000 [==============================] - 4s 51us/step - loss: 0.8022 - mean_absolute_error: 0.6961 - val_loss: 0.9278 - val_mean_absolute_error: 0.7477\n",
      "Epoch 40/80\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 0.7975 - mean_absolute_error: 0.6942 - val_loss: 0.9247 - val_mean_absolute_error: 0.7463\n",
      "Epoch 41/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7931 - mean_absolute_error: 0.6921 - val_loss: 0.9220 - val_mean_absolute_error: 0.7456\n",
      "Epoch 42/80\n",
      "70304/80000 [=========================>....] - ETA: 0s - loss: 0.7855 - mean_absolute_error: 0.688580000/80000 [==============================] - 4s 51us/step - loss: 0.7887 - mean_absolute_error: 0.6902 - val_loss: 0.9188 - val_mean_absolute_error: 0.7443\n",
      "Epoch 43/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7843 - mean_absolute_error: 0.6881 - val_loss: 0.9167 - val_mean_absolute_error: 0.7433\n",
      "Epoch 44/80\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 0.7801 - mean_absolute_error: 0.6863 - val_loss: 0.9145 - val_mean_absolute_error: 0.7422\n",
      "Epoch 45/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7759 - mean_absolute_error: 0.6842 - val_loss: 0.9123 - val_mean_absolute_error: 0.7415\n",
      "Epoch 46/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7716 - mean_absolute_error: 0.6820 - val_loss: 0.9110 - val_mean_absolute_error: 0.7414\n",
      "Epoch 47/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7674 - mean_absolute_error: 0.6798 - val_loss: 0.9092 - val_mean_absolute_error: 0.7410\n",
      "Epoch 48/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7632 - mean_absolute_error: 0.6779 - val_loss: 0.9069 - val_mean_absolute_error: 0.7402\n",
      "Epoch 49/80\n",
      "64192/80000 [=======================>......] - ETA: 0s - loss: 0.7593 - mean_absolute_error: 0.676380000/80000 [==============================] - 4s 52us/step - loss: 0.7589 - mean_absolute_error: 0.6761 - val_loss: 0.9046 - val_mean_absolute_error: 0.7389\n",
      "Epoch 50/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7548 - mean_absolute_error: 0.6741 - val_loss: 0.9034 - val_mean_absolute_error: 0.7382\n",
      "Epoch 51/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7508 - mean_absolute_error: 0.6718 - val_loss: 0.9022 - val_mean_absolute_error: 0.7382\n",
      "Epoch 52/80\n",
      "79456/80000 [============================>.] - ETA: 0s - loss: 0.7466 - mean_absolute_error: 0.669880000/80000 [==============================] - 4s 51us/step - loss: 0.7466 - mean_absolute_error: 0.6699 - val_loss: 0.9008 - val_mean_absolute_error: 0.7373\n",
      "Epoch 53/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7424 - mean_absolute_error: 0.6677 - val_loss: 0.8996 - val_mean_absolute_error: 0.7370\n",
      "Epoch 54/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7381 - mean_absolute_error: 0.6657 - val_loss: 0.8973 - val_mean_absolute_error: 0.7362\n",
      "Epoch 55/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7340 - mean_absolute_error: 0.6637 - val_loss: 0.8976 - val_mean_absolute_error: 0.7363\n",
      "Epoch 56/80\n",
      " 1024/80000 [..............................] - ETA: 4s - loss: 0.7573 - mean_absolute_error: 0.6772 80000/80000 [==============================] - 4s 51us/step - loss: 0.7300 - mean_absolute_error: 0.6617 - val_loss: 0.8950 - val_mean_absolute_error: 0.7354\n",
      "Epoch 57/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7256 - mean_absolute_error: 0.6593 - val_loss: 0.8941 - val_mean_absolute_error: 0.7346\n",
      "Epoch 58/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7216 - mean_absolute_error: 0.6571 - val_loss: 0.8931 - val_mean_absolute_error: 0.7348\n",
      "Epoch 59/80\n",
      "69696/80000 [=========================>....] - ETA: 0s - loss: 0.7160 - mean_absolute_error: 0.654380000/80000 [==============================] - 4s 51us/step - loss: 0.7174 - mean_absolute_error: 0.6552 - val_loss: 0.8914 - val_mean_absolute_error: 0.7337\n",
      "Epoch 60/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7131 - mean_absolute_error: 0.6529 - val_loss: 0.8910 - val_mean_absolute_error: 0.7336\n",
      "Epoch 61/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7088 - mean_absolute_error: 0.6508 - val_loss: 0.8892 - val_mean_absolute_error: 0.7329\n",
      "Epoch 62/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.7047 - mean_absolute_error: 0.6485 - val_loss: 0.8884 - val_mean_absolute_error: 0.7327\n",
      "Epoch 63/80\n",
      " 1152/80000 [..............................] - ETA: 4s - loss: 0.7008 - mean_absolute_error: 0.6556 80000/80000 [==============================] - 4s 51us/step - loss: 0.7003 - mean_absolute_error: 0.6464 - val_loss: 0.8879 - val_mean_absolute_error: 0.7322\n",
      "Epoch 64/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.6958 - mean_absolute_error: 0.6441 - val_loss: 0.8878 - val_mean_absolute_error: 0.7323\n",
      "Epoch 65/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.6916 - mean_absolute_error: 0.6417 - val_loss: 0.8867 - val_mean_absolute_error: 0.7318\n",
      "Epoch 66/80\n",
      "72288/80000 [==========================>...] - ETA: 0s - loss: 0.6871 - mean_absolute_error: 0.639480000/80000 [==============================] - 4s 51us/step - loss: 0.6873 - mean_absolute_error: 0.6393 - val_loss: 0.8857 - val_mean_absolute_error: 0.7314\n",
      "Epoch 67/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.6829 - mean_absolute_error: 0.6371 - val_loss: 0.8856 - val_mean_absolute_error: 0.7311\n",
      "Epoch 68/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.6785 - mean_absolute_error: 0.6347 - val_loss: 0.8848 - val_mean_absolute_error: 0.7310\n",
      "Epoch 69/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.6742 - mean_absolute_error: 0.6323 - val_loss: 0.8841 - val_mean_absolute_error: 0.7306\n",
      "Epoch 70/80\n",
      " 1056/80000 [..............................] - ETA: 4s - loss: 0.7061 - mean_absolute_error: 0.6382 80000/80000 [==============================] - 4s 51us/step - loss: 0.6699 - mean_absolute_error: 0.6302 - val_loss: 0.8834 - val_mean_absolute_error: 0.7307\n",
      "Epoch 71/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.6653 - mean_absolute_error: 0.6275 - val_loss: 0.8831 - val_mean_absolute_error: 0.7305\n",
      "Epoch 72/80\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.6609 - mean_absolute_error: 0.6253 - val_loss: 0.8830 - val_mean_absolute_error: 0.7306\n",
      "Epoch 73/80\n",
      "71456/80000 [=========================>....] - ETA: 0s - loss: 0.6556 - mean_absolute_error: 0.622780000/80000 [==============================] - 4s 51us/step - loss: 0.6567 - mean_absolute_error: 0.6228 - val_loss: 0.8821 - val_mean_absolute_error: 0.7303\n",
      "Epoch 74/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.6521 - mean_absolute_error: 0.6204 - val_loss: 0.8824 - val_mean_absolute_error: 0.7303\n",
      "Epoch 75/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.6477 - mean_absolute_error: 0.6178 - val_loss: 0.8823 - val_mean_absolute_error: 0.7302\n",
      "Epoch 76/80\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 0.6431 - mean_absolute_error: 0.6154 - val_loss: 0.8832 - val_mean_absolute_error: 0.7303\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping('val_loss', patience=3)]\n",
    "history = MF_model.fit([Users, Movies], Ratings, epochs=80, validation_split=.2, verbose=1, callbacks=callbacks, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5_7gdSRqKwL5"
   },
   "source": [
    "**Ex 1 Section A**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bVln6gpIoPT"
   },
   "source": [
    " **Average MAE for standard matrix factorization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1532808382973,
     "user": {
      "displayName": "Ran Tsur",
      "photoUrl": "//lh3.googleusercontent.com/-pkQ4mq31yyM/AAAAAAAAAAI/AAAAAAAAABg/OJrKb1aE-5Q/s50-c-k-no/photo.jpg",
      "userId": "106754954225433138332"
     },
     "user_tz": -180
    },
    "id": "syBEw8qMIsM4",
    "outputId": "1b7b4adb-dfd7-4be7-f8a2-5448fd566c65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE: 0.8414171710930373 and Min MAE 0.6153571675896644 in 76 epochs\n"
     ]
    }
   ],
   "source": [
    "print(\"Average MAE:\", np.mean(history.history['mean_absolute_error']),\\\n",
    "      \"and Min MAE\", min(history.history['mean_absolute_error']),\\\n",
    "      \"in\", len(history.history['mean_absolute_error']), \"epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V_-89O6fINvA"
   },
   "source": [
    "**Define generalized matrix factorization model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "pvUpM0o3-Mox"
   },
   "outputs": [],
   "source": [
    "def get_gmf_model(num_users, num_items, latent_dim,do):\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "\n",
    "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding', input_length=1)\n",
    "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding', input_length=1)   \n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(MF_Embedding_User(user_input))\n",
    "    item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
    "    \n",
    "    # Element-wise product of user and item embeddings\n",
    "    hidden1 = Multiply()([user_latent, item_latent])\n",
    "    drop = Dropout(do)(hidden1)\n",
    "    prediction = Dense(1, activation='relu', kernel_initializer='lecun_uniform', name = 'prediction')(drop)\n",
    "    \n",
    "    \n",
    "    model = Model(input=[user_input, item_input], output=prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGGjA9rRJIXD"
   },
   "source": [
    "** Ex 1 section B **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 4610
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 612118,
     "status": "ok",
     "timestamp": 1532809004288,
     "user": {
      "displayName": "Ran Tsur",
      "photoUrl": "//lh3.googleusercontent.com/-pkQ4mq31yyM/AAAAAAAAAAI/AAAAAAAAABg/OJrKb1aE-5Q/s50-c-k-no/photo.jpg",
      "userId": "106754954225433138332"
     },
     "user_tz": -180
    },
    "id": "LeEUzV79JGm3",
    "outputId": "08338a76-3920-4bb2-8c5a-b1511cdd3101"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"pr...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 4.7061 - mean_absolute_error: 1.8068 - val_loss: 1.3554 - val_mean_absolute_error: 0.9865\n",
      "Epoch 2/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 1.2517 - mean_absolute_error: 0.9405 - val_loss: 1.3305 - val_mean_absolute_error: 0.9697\n",
      "Epoch 3/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 1.2441 - mean_absolute_error: 0.9362 - val_loss: 1.3215 - val_mean_absolute_error: 0.9642\n",
      "Epoch 4/150\n",
      "28736/80000 [=========>....................] - ETA: 2s - loss: 1.2236 - mean_absolute_error: 0.926480000/80000 [==============================] - 4s 54us/step - loss: 1.2158 - mean_absolute_error: 0.9232 - val_loss: 1.2891 - val_mean_absolute_error: 0.9519\n",
      "Epoch 5/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 1.1540 - mean_absolute_error: 0.8924 - val_loss: 1.2284 - val_mean_absolute_error: 0.9209\n",
      "Epoch 6/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 1.0930 - mean_absolute_error: 0.8578 - val_loss: 1.1754 - val_mean_absolute_error: 0.8931\n",
      "Epoch 7/150\n",
      "62656/80000 [======================>.......] - ETA: 0s - loss: 1.0578 - mean_absolute_error: 0.836880000/80000 [==============================] - 4s 55us/step - loss: 1.0521 - mean_absolute_error: 0.8338 - val_loss: 1.1387 - val_mean_absolute_error: 0.8717\n",
      "Epoch 8/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 1.0200 - mean_absolute_error: 0.8152 - val_loss: 1.1093 - val_mean_absolute_error: 0.8538\n",
      "Epoch 9/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.9920 - mean_absolute_error: 0.7993 - val_loss: 1.0850 - val_mean_absolute_error: 0.8390\n",
      "Epoch 10/150\n",
      "64832/80000 [=======================>......] - ETA: 0s - loss: 0.9666 - mean_absolute_error: 0.785880000/80000 [==============================] - 4s 56us/step - loss: 0.9681 - mean_absolute_error: 0.7862 - val_loss: 1.0647 - val_mean_absolute_error: 0.8277\n",
      "Epoch 11/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.9468 - mean_absolute_error: 0.7752 - val_loss: 1.0470 - val_mean_absolute_error: 0.8184\n",
      "Epoch 12/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.9262 - mean_absolute_error: 0.7651 - val_loss: 1.0310 - val_mean_absolute_error: 0.8105\n",
      "Epoch 13/150\n",
      "64576/80000 [=======================>......] - ETA: 0s - loss: 0.9101 - mean_absolute_error: 0.756880000/80000 [==============================] - 4s 55us/step - loss: 0.9094 - mean_absolute_error: 0.7563 - val_loss: 1.0170 - val_mean_absolute_error: 0.8029\n",
      "Epoch 14/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.8949 - mean_absolute_error: 0.7492 - val_loss: 1.0050 - val_mean_absolute_error: 0.7973\n",
      "Epoch 15/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.8754 - mean_absolute_error: 0.7402 - val_loss: 0.9951 - val_mean_absolute_error: 0.7924\n",
      "Epoch 16/150\n",
      "65216/80000 [=======================>......] - ETA: 0s - loss: 0.8655 - mean_absolute_error: 0.734580000/80000 [==============================] - 5s 56us/step - loss: 0.8657 - mean_absolute_error: 0.7353 - val_loss: 0.9863 - val_mean_absolute_error: 0.7881\n",
      "Epoch 17/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.8552 - mean_absolute_error: 0.7308 - val_loss: 0.9786 - val_mean_absolute_error: 0.7850\n",
      "Epoch 18/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.8468 - mean_absolute_error: 0.7270 - val_loss: 0.9717 - val_mean_absolute_error: 0.7808\n",
      "Epoch 19/150\n",
      "64704/80000 [=======================>......] - ETA: 0s - loss: 0.8335 - mean_absolute_error: 0.721280000/80000 [==============================] - 4s 56us/step - loss: 0.8367 - mean_absolute_error: 0.7219 - val_loss: 0.9663 - val_mean_absolute_error: 0.7793\n",
      "Epoch 20/150\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 0.8296 - mean_absolute_error: 0.7194 - val_loss: 0.9613 - val_mean_absolute_error: 0.7775\n",
      "Epoch 21/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.8258 - mean_absolute_error: 0.7164 - val_loss: 0.9569 - val_mean_absolute_error: 0.7748\n",
      "Epoch 22/150\n",
      "64256/80000 [=======================>......] - ETA: 0s - loss: 0.8157 - mean_absolute_error: 0.711880000/80000 [==============================] - 4s 56us/step - loss: 0.8147 - mean_absolute_error: 0.7113 - val_loss: 0.9529 - val_mean_absolute_error: 0.7729\n",
      "Epoch 23/150\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 0.8119 - mean_absolute_error: 0.7099 - val_loss: 0.9502 - val_mean_absolute_error: 0.7715\n",
      "Epoch 24/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.8044 - mean_absolute_error: 0.7060 - val_loss: 0.9471 - val_mean_absolute_error: 0.7692\n",
      "Epoch 25/150\n",
      "61536/80000 [======================>.......] - ETA: 0s - loss: 0.7951 - mean_absolute_error: 0.701380000/80000 [==============================] - 5s 57us/step - loss: 0.7967 - mean_absolute_error: 0.7024 - val_loss: 0.9439 - val_mean_absolute_error: 0.7676\n",
      "Epoch 26/150\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 0.7952 - mean_absolute_error: 0.7013 - val_loss: 0.9417 - val_mean_absolute_error: 0.7680\n",
      "Epoch 27/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.7905 - mean_absolute_error: 0.6977 - val_loss: 0.9399 - val_mean_absolute_error: 0.7667\n",
      "Epoch 28/150\n",
      "64128/80000 [=======================>......] - ETA: 0s - loss: 0.7844 - mean_absolute_error: 0.696280000/80000 [==============================] - 4s 56us/step - loss: 0.7852 - mean_absolute_error: 0.6968 - val_loss: 0.9379 - val_mean_absolute_error: 0.7655\n",
      "Epoch 29/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.7785 - mean_absolute_error: 0.6934 - val_loss: 0.9360 - val_mean_absolute_error: 0.7642\n",
      "Epoch 30/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7769 - mean_absolute_error: 0.6918 - val_loss: 0.9349 - val_mean_absolute_error: 0.7641\n",
      "Epoch 31/150\n",
      "65952/80000 [=======================>......] - ETA: 0s - loss: 0.7737 - mean_absolute_error: 0.690280000/80000 [==============================] - 4s 55us/step - loss: 0.7731 - mean_absolute_error: 0.6906 - val_loss: 0.9330 - val_mean_absolute_error: 0.7628\n",
      "Epoch 32/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.7713 - mean_absolute_error: 0.6891 - val_loss: 0.9323 - val_mean_absolute_error: 0.7633\n",
      "Epoch 33/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7664 - mean_absolute_error: 0.6864 - val_loss: 0.9309 - val_mean_absolute_error: 0.7623\n",
      "Epoch 34/150\n",
      "66624/80000 [=======================>......] - ETA: 0s - loss: 0.7604 - mean_absolute_error: 0.684680000/80000 [==============================] - 4s 55us/step - loss: 0.7637 - mean_absolute_error: 0.6860 - val_loss: 0.9300 - val_mean_absolute_error: 0.7610\n",
      "Epoch 35/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7607 - mean_absolute_error: 0.6839 - val_loss: 0.9289 - val_mean_absolute_error: 0.7620\n",
      "Epoch 36/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7571 - mean_absolute_error: 0.6826 - val_loss: 0.9277 - val_mean_absolute_error: 0.7604\n",
      "Epoch 37/150\n",
      "67584/80000 [========================>.....] - ETA: 0s - loss: 0.7574 - mean_absolute_error: 0.681880000/80000 [==============================] - 4s 55us/step - loss: 0.7602 - mean_absolute_error: 0.6831 - val_loss: 0.9282 - val_mean_absolute_error: 0.7604\n",
      "Epoch 38/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7560 - mean_absolute_error: 0.6820 - val_loss: 0.9269 - val_mean_absolute_error: 0.7600\n",
      "Epoch 39/150\n",
      "80000/80000 [==============================] - 4s 54us/step - loss: 0.7496 - mean_absolute_error: 0.6780 - val_loss: 0.9262 - val_mean_absolute_error: 0.7601\n",
      "Epoch 40/150\n",
      "67136/80000 [========================>.....] - ETA: 0s - loss: 0.7483 - mean_absolute_error: 0.677880000/80000 [==============================] - 4s 55us/step - loss: 0.7481 - mean_absolute_error: 0.6777 - val_loss: 0.9257 - val_mean_absolute_error: 0.7597\n",
      "Epoch 41/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7441 - mean_absolute_error: 0.6749 - val_loss: 0.9250 - val_mean_absolute_error: 0.7589\n",
      "Epoch 42/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7422 - mean_absolute_error: 0.6741 - val_loss: 0.9246 - val_mean_absolute_error: 0.7593\n",
      "Epoch 43/150\n",
      "68128/80000 [========================>.....] - ETA: 0s - loss: 0.7372 - mean_absolute_error: 0.671780000/80000 [==============================] - 4s 55us/step - loss: 0.7385 - mean_absolute_error: 0.6723 - val_loss: 0.9244 - val_mean_absolute_error: 0.7596\n",
      "Epoch 44/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7406 - mean_absolute_error: 0.6735 - val_loss: 0.9240 - val_mean_absolute_error: 0.7588\n",
      "Epoch 45/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7377 - mean_absolute_error: 0.6710 - val_loss: 0.9236 - val_mean_absolute_error: 0.7578\n",
      "Epoch 46/150\n",
      "68032/80000 [========================>.....] - ETA: 0s - loss: 0.7355 - mean_absolute_error: 0.671380000/80000 [==============================] - 4s 55us/step - loss: 0.7354 - mean_absolute_error: 0.6713 - val_loss: 0.9235 - val_mean_absolute_error: 0.7586\n",
      "Epoch 47/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7349 - mean_absolute_error: 0.6715 - val_loss: 0.9231 - val_mean_absolute_error: 0.7586\n",
      "Epoch 48/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7305 - mean_absolute_error: 0.6691 - val_loss: 0.9221 - val_mean_absolute_error: 0.7577\n",
      "Epoch 49/150\n",
      "68224/80000 [========================>.....] - ETA: 0s - loss: 0.7260 - mean_absolute_error: 0.666980000/80000 [==============================] - 4s 55us/step - loss: 0.7290 - mean_absolute_error: 0.6685 - val_loss: 0.9209 - val_mean_absolute_error: 0.7579\n",
      "Epoch 50/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7256 - mean_absolute_error: 0.6671 - val_loss: 0.9215 - val_mean_absolute_error: 0.7568\n",
      "Epoch 51/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7267 - mean_absolute_error: 0.6666 - val_loss: 0.9206 - val_mean_absolute_error: 0.7569\n",
      "Epoch 52/150\n",
      "67712/80000 [========================>.....] - ETA: 0s - loss: 0.7289 - mean_absolute_error: 0.668080000/80000 [==============================] - 4s 56us/step - loss: 0.7313 - mean_absolute_error: 0.6689 - val_loss: 0.9205 - val_mean_absolute_error: 0.7559\n",
      "Epoch 53/150\n",
      "80000/80000 [==============================] - 4s 54us/step - loss: 0.7269 - mean_absolute_error: 0.6658 - val_loss: 0.9198 - val_mean_absolute_error: 0.7570\n",
      "Epoch 54/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7240 - mean_absolute_error: 0.6643 - val_loss: 0.9200 - val_mean_absolute_error: 0.7565\n",
      "Epoch 55/150\n",
      "68480/80000 [========================>.....] - ETA: 0s - loss: 0.7199 - mean_absolute_error: 0.662680000/80000 [==============================] - 4s 55us/step - loss: 0.7226 - mean_absolute_error: 0.6643 - val_loss: 0.9201 - val_mean_absolute_error: 0.7570\n",
      "Epoch 56/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7243 - mean_absolute_error: 0.6659 - val_loss: 0.9199 - val_mean_absolute_error: 0.7567\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 4.7044 - mean_absolute_error: 1.8032 - val_loss: 1.3475 - val_mean_absolute_error: 0.9830\n",
      "Epoch 2/150\n",
      "47456/80000 [================>.............] - ETA: 1s - loss: 1.2498 - mean_absolute_error: 0.940180000/80000 [==============================] - 5s 59us/step - loss: 1.2507 - mean_absolute_error: 0.9397 - val_loss: 1.3290 - val_mean_absolute_error: 0.9679\n",
      "Epoch 3/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 1.2386 - mean_absolute_error: 0.9338 - val_loss: 1.3134 - val_mean_absolute_error: 0.9607\n",
      "Epoch 4/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 1.1955 - mean_absolute_error: 0.9136 - val_loss: 1.2647 - val_mean_absolute_error: 0.9403\n",
      "Epoch 5/150\n",
      "50432/80000 [=================>............] - ETA: 1s - loss: 1.1377 - mean_absolute_error: 0.883880000/80000 [==============================] - 5s 60us/step - loss: 1.1201 - mean_absolute_error: 0.8746 - val_loss: 1.1969 - val_mean_absolute_error: 0.9047\n",
      "Epoch 6/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 1.0568 - mean_absolute_error: 0.8383 - val_loss: 1.1447 - val_mean_absolute_error: 0.8749\n",
      "Epoch 7/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 1.0087 - mean_absolute_error: 0.8106 - val_loss: 1.1051 - val_mean_absolute_error: 0.8522\n",
      "Epoch 8/150\n",
      "51552/80000 [==================>...........] - ETA: 1s - loss: 0.9789 - mean_absolute_error: 0.792780000/80000 [==============================] - 5s 60us/step - loss: 0.9697 - mean_absolute_error: 0.7883 - val_loss: 1.0732 - val_mean_absolute_error: 0.8341\n",
      "Epoch 9/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9304 - mean_absolute_error: 0.7675 - val_loss: 1.0445 - val_mean_absolute_error: 0.8176\n",
      "Epoch 10/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9002 - mean_absolute_error: 0.7528 - val_loss: 1.0216 - val_mean_absolute_error: 0.8060\n",
      "Epoch 11/150\n",
      "51936/80000 [==================>...........] - ETA: 1s - loss: 0.8714 - mean_absolute_error: 0.738980000/80000 [==============================] - 5s 60us/step - loss: 0.8730 - mean_absolute_error: 0.7392 - val_loss: 1.0020 - val_mean_absolute_error: 0.7959\n",
      "Epoch 12/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8491 - mean_absolute_error: 0.7277 - val_loss: 0.9869 - val_mean_absolute_error: 0.7881\n",
      "Epoch 13/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8313 - mean_absolute_error: 0.7187 - val_loss: 0.9754 - val_mean_absolute_error: 0.7817\n",
      "Epoch 14/150\n",
      "50592/80000 [=================>............] - ETA: 1s - loss: 0.8154 - mean_absolute_error: 0.710580000/80000 [==============================] - 5s 61us/step - loss: 0.8157 - mean_absolute_error: 0.7115 - val_loss: 0.9662 - val_mean_absolute_error: 0.7790\n",
      "Epoch 15/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.8031 - mean_absolute_error: 0.7047 - val_loss: 0.9573 - val_mean_absolute_error: 0.7749\n",
      "Epoch 16/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.7907 - mean_absolute_error: 0.6993 - val_loss: 0.9507 - val_mean_absolute_error: 0.7717\n",
      "Epoch 17/150\n",
      "50080/80000 [=================>............] - ETA: 1s - loss: 0.7749 - mean_absolute_error: 0.690380000/80000 [==============================] - 5s 60us/step - loss: 0.7789 - mean_absolute_error: 0.6930 - val_loss: 0.9457 - val_mean_absolute_error: 0.7680\n",
      "Epoch 18/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.7671 - mean_absolute_error: 0.6873 - val_loss: 0.9420 - val_mean_absolute_error: 0.7664\n",
      "Epoch 19/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.7563 - mean_absolute_error: 0.6818 - val_loss: 0.9376 - val_mean_absolute_error: 0.7646\n",
      "Epoch 20/150\n",
      "46944/80000 [================>.............] - ETA: 1s - loss: 0.7513 - mean_absolute_error: 0.679580000/80000 [==============================] - 5s 61us/step - loss: 0.7540 - mean_absolute_error: 0.6806 - val_loss: 0.9344 - val_mean_absolute_error: 0.7627\n",
      "Epoch 21/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.7440 - mean_absolute_error: 0.6760 - val_loss: 0.9318 - val_mean_absolute_error: 0.7629\n",
      "Epoch 22/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.7395 - mean_absolute_error: 0.6739 - val_loss: 0.9293 - val_mean_absolute_error: 0.7604\n",
      "Epoch 23/150\n",
      "47712/80000 [================>.............] - ETA: 1s - loss: 0.7289 - mean_absolute_error: 0.666980000/80000 [==============================] - 5s 61us/step - loss: 0.7329 - mean_absolute_error: 0.6696 - val_loss: 0.9276 - val_mean_absolute_error: 0.7595\n",
      "Epoch 24/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.7255 - mean_absolute_error: 0.6672 - val_loss: 0.9263 - val_mean_absolute_error: 0.7588\n",
      "Epoch 25/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.7175 - mean_absolute_error: 0.6628 - val_loss: 0.9249 - val_mean_absolute_error: 0.7590\n",
      "Epoch 26/150\n",
      "48544/80000 [=================>............] - ETA: 1s - loss: 0.7097 - mean_absolute_error: 0.659180000/80000 [==============================] - 5s 61us/step - loss: 0.7136 - mean_absolute_error: 0.6605 - val_loss: 0.9239 - val_mean_absolute_error: 0.7576\n",
      "Epoch 27/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.7107 - mean_absolute_error: 0.6591 - val_loss: 0.9227 - val_mean_absolute_error: 0.7565\n",
      "Epoch 28/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.7029 - mean_absolute_error: 0.6558 - val_loss: 0.9204 - val_mean_absolute_error: 0.7566\n",
      "Epoch 29/150\n",
      "48800/80000 [=================>............] - ETA: 1s - loss: 0.6962 - mean_absolute_error: 0.652380000/80000 [==============================] - 5s 60us/step - loss: 0.6986 - mean_absolute_error: 0.6528 - val_loss: 0.9185 - val_mean_absolute_error: 0.7560\n",
      "Epoch 30/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.6969 - mean_absolute_error: 0.6522 - val_loss: 0.9179 - val_mean_absolute_error: 0.7547\n",
      "Epoch 31/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.6894 - mean_absolute_error: 0.6479 - val_loss: 0.9175 - val_mean_absolute_error: 0.7547\n",
      "Epoch 32/150\n",
      "50016/80000 [=================>............] - ETA: 1s - loss: 0.6840 - mean_absolute_error: 0.645780000/80000 [==============================] - 5s 60us/step - loss: 0.6899 - mean_absolute_error: 0.6491 - val_loss: 0.9169 - val_mean_absolute_error: 0.7546\n",
      "Epoch 33/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.6800 - mean_absolute_error: 0.6439 - val_loss: 0.9167 - val_mean_absolute_error: 0.7550\n",
      "Epoch 34/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.6807 - mean_absolute_error: 0.6440 - val_loss: 0.9171 - val_mean_absolute_error: 0.7541\n",
      "Epoch 35/150\n",
      "50176/80000 [=================>............] - ETA: 1s - loss: 0.6705 - mean_absolute_error: 0.638280000/80000 [==============================] - 5s 60us/step - loss: 0.6729 - mean_absolute_error: 0.6400 - val_loss: 0.9169 - val_mean_absolute_error: 0.7545\n",
      "Epoch 36/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.6722 - mean_absolute_error: 0.6394 - val_loss: 0.9167 - val_mean_absolute_error: 0.7537\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 4.6556 - mean_absolute_error: 1.7940 - val_loss: 1.3484 - val_mean_absolute_error: 0.9835\n",
      "Epoch 2/150\n",
      "47200/80000 [================>.............] - ETA: 1s - loss: 1.2450 - mean_absolute_error: 0.938680000/80000 [==============================] - 4s 56us/step - loss: 1.2424 - mean_absolute_error: 0.9364 - val_loss: 1.3114 - val_mean_absolute_error: 0.9586\n",
      "Epoch 3/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 1.1813 - mean_absolute_error: 0.9063 - val_loss: 1.2353 - val_mean_absolute_error: 0.9260\n",
      "Epoch 4/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 1.0839 - mean_absolute_error: 0.8536 - val_loss: 1.1566 - val_mean_absolute_error: 0.8820\n",
      "Epoch 5/150\n",
      "63712/80000 [======================>.......] - ETA: 0s - loss: 1.0210 - mean_absolute_error: 0.817380000/80000 [==============================] - 4s 56us/step - loss: 1.0165 - mean_absolute_error: 0.8150 - val_loss: 1.1038 - val_mean_absolute_error: 0.8499\n",
      "Epoch 6/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.9602 - mean_absolute_error: 0.7830 - val_loss: 1.0613 - val_mean_absolute_error: 0.8255\n",
      "Epoch 7/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.9095 - mean_absolute_error: 0.7565 - val_loss: 1.0256 - val_mean_absolute_error: 0.8059\n",
      "Epoch 8/150\n",
      "65088/80000 [=======================>......] - ETA: 0s - loss: 0.8664 - mean_absolute_error: 0.736380000/80000 [==============================] - 4s 56us/step - loss: 0.8653 - mean_absolute_error: 0.7357 - val_loss: 0.9987 - val_mean_absolute_error: 0.7916\n",
      "Epoch 9/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.8305 - mean_absolute_error: 0.7190 - val_loss: 0.9798 - val_mean_absolute_error: 0.7819\n",
      "Epoch 10/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.8007 - mean_absolute_error: 0.7047 - val_loss: 0.9660 - val_mean_absolute_error: 0.7758\n",
      "Epoch 11/150\n",
      "65280/80000 [=======================>......] - ETA: 0s - loss: 0.7793 - mean_absolute_error: 0.693680000/80000 [==============================] - 4s 56us/step - loss: 0.7781 - mean_absolute_error: 0.6931 - val_loss: 0.9563 - val_mean_absolute_error: 0.7701\n",
      "Epoch 12/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7554 - mean_absolute_error: 0.6820 - val_loss: 0.9497 - val_mean_absolute_error: 0.7671\n",
      "Epoch 13/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.7355 - mean_absolute_error: 0.6724 - val_loss: 0.9445 - val_mean_absolute_error: 0.7654\n",
      "Epoch 14/150\n",
      "65696/80000 [=======================>......] - ETA: 0s - loss: 0.7207 - mean_absolute_error: 0.664380000/80000 [==============================] - 4s 56us/step - loss: 0.7181 - mean_absolute_error: 0.6635 - val_loss: 0.9407 - val_mean_absolute_error: 0.7630\n",
      "Epoch 15/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.7035 - mean_absolute_error: 0.6561 - val_loss: 0.9385 - val_mean_absolute_error: 0.7627\n",
      "Epoch 16/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.6896 - mean_absolute_error: 0.6484 - val_loss: 0.9368 - val_mean_absolute_error: 0.7612\n",
      "Epoch 17/150\n",
      "66816/80000 [========================>.....] - ETA: 0s - loss: 0.6730 - mean_absolute_error: 0.640580000/80000 [==============================] - 4s 55us/step - loss: 0.6752 - mean_absolute_error: 0.6410 - val_loss: 0.9362 - val_mean_absolute_error: 0.7603\n",
      "Epoch 18/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.6642 - mean_absolute_error: 0.6355 - val_loss: 0.9360 - val_mean_absolute_error: 0.7596\n",
      "Epoch 19/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.6558 - mean_absolute_error: 0.6312 - val_loss: 0.9363 - val_mean_absolute_error: 0.7591\n",
      "Epoch 20/150\n",
      "65856/80000 [=======================>......] - ETA: 0s - loss: 0.6397 - mean_absolute_error: 0.622180000/80000 [==============================] - 4s 55us/step - loss: 0.6449 - mean_absolute_error: 0.6239 - val_loss: 0.9369 - val_mean_absolute_error: 0.7604\n",
      "Epoch 21/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.6368 - mean_absolute_error: 0.6198 - val_loss: 0.9377 - val_mean_absolute_error: 0.7603\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 4.7170 - mean_absolute_error: 1.8079 - val_loss: 1.3527 - val_mean_absolute_error: 0.9854\n",
      "Epoch 2/150\n",
      "43168/80000 [===============>..............] - ETA: 2s - loss: 1.2476 - mean_absolute_error: 0.939480000/80000 [==============================] - 5s 61us/step - loss: 1.2315 - mean_absolute_error: 0.9317 - val_loss: 1.2891 - val_mean_absolute_error: 0.9517\n",
      "Epoch 3/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 1.1371 - mean_absolute_error: 0.8832 - val_loss: 1.1854 - val_mean_absolute_error: 0.8985\n",
      "Epoch 4/150\n",
      "80000/80000 [==============================] - 5s 63us/step - loss: 1.0430 - mean_absolute_error: 0.8294 - val_loss: 1.1174 - val_mean_absolute_error: 0.8583\n",
      "Epoch 5/150\n",
      "43488/80000 [===============>..............] - ETA: 2s - loss: 0.9890 - mean_absolute_error: 0.797680000/80000 [==============================] - 5s 63us/step - loss: 0.9813 - mean_absolute_error: 0.7936 - val_loss: 1.0716 - val_mean_absolute_error: 0.8308\n",
      "Epoch 6/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.9257 - mean_absolute_error: 0.7641 - val_loss: 1.0330 - val_mean_absolute_error: 0.8097\n",
      "Epoch 7/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.8714 - mean_absolute_error: 0.7377 - val_loss: 1.0002 - val_mean_absolute_error: 0.7926\n",
      "Epoch 8/150\n",
      "46304/80000 [================>.............] - ETA: 1s - loss: 0.8280 - mean_absolute_error: 0.716580000/80000 [==============================] - 5s 61us/step - loss: 0.8243 - mean_absolute_error: 0.7153 - val_loss: 0.9762 - val_mean_absolute_error: 0.7814\n",
      "Epoch 9/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.7834 - mean_absolute_error: 0.6958 - val_loss: 0.9587 - val_mean_absolute_error: 0.7726\n",
      "Epoch 10/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.7493 - mean_absolute_error: 0.6794 - val_loss: 0.9464 - val_mean_absolute_error: 0.7668\n",
      "Epoch 11/150\n",
      "47424/80000 [================>.............] - ETA: 1s - loss: 0.7115 - mean_absolute_error: 0.659680000/80000 [==============================] - 5s 61us/step - loss: 0.7174 - mean_absolute_error: 0.6631 - val_loss: 0.9379 - val_mean_absolute_error: 0.7632\n",
      "Epoch 12/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.6910 - mean_absolute_error: 0.6504 - val_loss: 0.9319 - val_mean_absolute_error: 0.7603\n",
      "Epoch 13/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.6692 - mean_absolute_error: 0.6382 - val_loss: 0.9282 - val_mean_absolute_error: 0.7574\n",
      "Epoch 14/150\n",
      "47328/80000 [================>.............] - ETA: 1s - loss: 0.6469 - mean_absolute_error: 0.627280000/80000 [==============================] - 5s 62us/step - loss: 0.6478 - mean_absolute_error: 0.6268 - val_loss: 0.9256 - val_mean_absolute_error: 0.7564\n",
      "Epoch 15/150\n",
      "80000/80000 [==============================] - 5s 63us/step - loss: 0.6289 - mean_absolute_error: 0.6171 - val_loss: 0.9255 - val_mean_absolute_error: 0.7553\n",
      "Epoch 16/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.6098 - mean_absolute_error: 0.6072 - val_loss: 0.9255 - val_mean_absolute_error: 0.7560\n",
      "Epoch 17/150\n",
      "45856/80000 [================>.............] - ETA: 1s - loss: 0.5892 - mean_absolute_error: 0.596280000/80000 [==============================] - 5s 62us/step - loss: 0.5960 - mean_absolute_error: 0.5987 - val_loss: 0.9257 - val_mean_absolute_error: 0.7551\n",
      "Epoch 18/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.5797 - mean_absolute_error: 0.5899 - val_loss: 0.9271 - val_mean_absolute_error: 0.7549\n",
      "Epoch 19/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.5659 - mean_absolute_error: 0.5824 - val_loss: 0.9294 - val_mean_absolute_error: 0.7562\n"
     ]
    }
   ],
   "source": [
    "k_latents = [20, 30]\n",
    "dos = [0.5, 0.2]\n",
    "GMF_results = []\n",
    "for do in dos:\n",
    "  for k in k_latents:\n",
    "    GMF_model = get_gmf_model(max_userid,max_movieid,k,do)\n",
    "    GMF_model.compile(loss='mse',optimizer=Adamax(),metrics=['mae'])\n",
    "    callbacks = [EarlyStopping('val_loss', patience=3)]\n",
    "    GMF_history = GMF_model.fit([Users, Movies], Ratings, epochs=150, validation_split=.2, verbose=1, callbacks=callbacks, batch_size = 32)\n",
    "    GMF_results.append((k, do, GMF_history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EAKBBzk9Jcyd"
   },
   "source": [
    "**Average MAE for generalized matrix factorization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 701,
     "status": "ok",
     "timestamp": 1532585106914,
     "user": {
      "displayName": "Ran Tsur",
      "photoUrl": "//lh3.googleusercontent.com/-pkQ4mq31yyM/AAAAAAAAAAI/AAAAAAAAABg/OJrKb1aE-5Q/s50-c-k-no/photo.jpg",
      "userId": "106754954225433138332"
     },
     "user_tz": -180
    },
    "id": "z-u5itrsJfWe",
    "outputId": "4c7e159b-8338-4462-a18c-d19baa8ab30b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20 latent dimension in 51 epochs and 0.5 drop out Average MAE: 0.7466326880896792 and Min MAE 0.6677943883299827\n",
      "Using 30 latent dimension in 42 epochs and 0.5 drop out Average MAE: 0.7344445350505057 and Min MAE 0.6331295590162277\n",
      "Using 20 latent dimension in 20 epochs and 0.2 drop out Average MAE: 0.7768717128753662 and Min MAE 0.6205486805081367\n",
      "Using 30 latent dimension in 19 epochs and 0.2 drop out Average MAE: 0.7597886738143469 and Min MAE 0.57933232640028\n"
     ]
    }
   ],
   "source": [
    "for k, do, history in GMF_results:\n",
    "  avg = np.mean(history.history['mean_absolute_error'])\n",
    "  epochs = len(history.history['mean_absolute_error'])\n",
    "  minimum = min(history.history['mean_absolute_error'])\n",
    "  print(\"Using\", k, \"latent dimension in\", epochs, \"epochs and\", do, \"drop out Average MAE:\", avg, \"and Min MAE\", minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vBxphxPvMYnC"
   },
   "source": [
    "**Ex 1 Section C**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhEUpAoWMfQt"
   },
   "source": [
    "Using Matrix Factorization, the average MAE was 0.84 with minimal MAE of 0.6166\n",
    "\n",
    "Using GMF's best run, the average MAE was 0.7597 with minimal MAE of 0.5793\n",
    "\n",
    "Ass 2 - the average MAE was 0.8272\n",
    "\n",
    "We saw that the time to train the new models - GMF and MF - are lonager than the model's train of ass 2 - minutes vs seconds.\n",
    "\n",
    "By the results of the min MAE, we can say that the new models are better than ass 2 model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Nxz6tjqjrI_"
   },
   "source": [
    "**Define neural collaborative filtering model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Euhy_Kg--Mo1"
   },
   "outputs": [],
   "source": [
    "def get_ncf_model(num_users, num_items, latent_dim, hidden_dim, do):\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "\n",
    "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding', input_length=1)\n",
    "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding', input_length=1)   \n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(MF_Embedding_User(user_input))\n",
    "    item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
    "    \n",
    "    # Element-wise product of user and item embeddings\n",
    "    conc = Concatenate()([user_latent, item_latent])\n",
    "    drop = Dropout(0.5)(conc)\n",
    "    hid1 = Dense(hidden_dim, activation='relu')(conc)\n",
    "    drop2  = Dropout(do)(hid1)\n",
    "    prediction = Dense(1, activation='relu', kernel_initializer='lecun_uniform', name = 'prediction')(drop2)\n",
    "    \n",
    "    \n",
    "    model = Model(input=[user_input, item_input], output=prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j5CO9_XwPrNZ"
   },
   "source": [
    "##Ex 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ULE-yQNRPzso"
   },
   "outputs": [],
   "source": [
    "def get_ncf_model(num_users, num_items, latent_dim, hidden_dim, do, num_of_hidden):\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "\n",
    "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding', input_length=1)\n",
    "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding', input_length=1)   \n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(MF_Embedding_User(user_input))\n",
    "    item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
    "    \n",
    "    # Element-wise product of user and item embeddings\n",
    "    conc = Concatenate()([user_latent, item_latent])\n",
    "    drop = Dropout(0.5)(conc)\n",
    "    hid1 = Dense(hidden_dim, activation='relu')(drop)\n",
    "    last_layer = hid1\n",
    "    for i in range(num_of_hidden - 1):\n",
    "      hid_n = Dense(hidden_dim, activation='relu')(last_layer)\n",
    "      last_layer = hid_n\n",
    "    drop2  = Dropout(do)(last_layer)\n",
    "    prediction = Dense(1, activation='relu', kernel_initializer='lecun_uniform', name = 'prediction')(drop2)\n",
    "    \n",
    "    model = Model(inputs=[user_input, item_input], outputs=prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 8027
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 1121585,
     "status": "ok",
     "timestamp": 1532810525249,
     "user": {
      "displayName": "Ran Tsur",
      "photoUrl": "//lh3.googleusercontent.com/-pkQ4mq31yyM/AAAAAAAAAAI/AAAAAAAAABg/OJrKb1aE-5Q/s50-c-k-no/photo.jpg",
      "userId": "106754954225433138332"
     },
     "user_tz": -180
    },
    "id": "CZpLH-TLP4HS",
    "outputId": "9aa39258-93cc-4e4b-e248-c076815889be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 6s 70us/step - loss: 2.6919 - mean_absolute_error: 1.3034 - val_loss: 1.1339 - val_mean_absolute_error: 0.8821\n",
      "Epoch 2/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 1.2526 - mean_absolute_error: 0.9045 - val_loss: 1.0109 - val_mean_absolute_error: 0.8165\n",
      "Epoch 3/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 1.0381 - mean_absolute_error: 0.8187 - val_loss: 0.9704 - val_mean_absolute_error: 0.7896\n",
      "Epoch 4/150\n",
      "14752/80000 [====>.........................] - ETA: 3s - loss: 0.9960 - mean_absolute_error: 0.799580000/80000 [==============================] - 5s 62us/step - loss: 0.9726 - mean_absolute_error: 0.7889 - val_loss: 0.9454 - val_mean_absolute_error: 0.7762\n",
      "Epoch 5/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.9443 - mean_absolute_error: 0.7750 - val_loss: 0.9375 - val_mean_absolute_error: 0.7707\n",
      "Epoch 6/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.9303 - mean_absolute_error: 0.7678 - val_loss: 0.9300 - val_mean_absolute_error: 0.7648\n",
      "Epoch 7/150\n",
      "45088/80000 [===============>..............] - ETA: 1s - loss: 0.9259 - mean_absolute_error: 0.763780000/80000 [==============================] - 5s 61us/step - loss: 0.9299 - mean_absolute_error: 0.7662 - val_loss: 0.9264 - val_mean_absolute_error: 0.7636\n",
      "Epoch 8/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.9223 - mean_absolute_error: 0.7640 - val_loss: 0.9241 - val_mean_absolute_error: 0.7627\n",
      "Epoch 9/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.9192 - mean_absolute_error: 0.7615 - val_loss: 0.9210 - val_mean_absolute_error: 0.7611\n",
      "Epoch 10/150\n",
      "48288/80000 [=================>............] - ETA: 1s - loss: 0.9189 - mean_absolute_error: 0.760880000/80000 [==============================] - 5s 62us/step - loss: 0.9179 - mean_absolute_error: 0.7604 - val_loss: 0.9185 - val_mean_absolute_error: 0.7577\n",
      "Epoch 11/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.9121 - mean_absolute_error: 0.7583 - val_loss: 0.9161 - val_mean_absolute_error: 0.7580\n",
      "Epoch 12/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.9121 - mean_absolute_error: 0.7588 - val_loss: 0.9202 - val_mean_absolute_error: 0.7596\n",
      "Epoch 13/150\n",
      "46720/80000 [================>.............] - ETA: 1s - loss: 0.9054 - mean_absolute_error: 0.754680000/80000 [==============================] - 5s 62us/step - loss: 0.9078 - mean_absolute_error: 0.7566 - val_loss: 0.9122 - val_mean_absolute_error: 0.7573\n",
      "Epoch 14/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.9086 - mean_absolute_error: 0.7571 - val_loss: 0.9132 - val_mean_absolute_error: 0.7578\n",
      "Epoch 15/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.9047 - mean_absolute_error: 0.7557 - val_loss: 0.9106 - val_mean_absolute_error: 0.7581\n",
      "Epoch 16/150\n",
      "48544/80000 [=================>............] - ETA: 1s - loss: 0.8962 - mean_absolute_error: 0.752180000/80000 [==============================] - 5s 61us/step - loss: 0.9015 - mean_absolute_error: 0.7543 - val_loss: 0.9079 - val_mean_absolute_error: 0.7531\n",
      "Epoch 17/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.9013 - mean_absolute_error: 0.7535 - val_loss: 0.9075 - val_mean_absolute_error: 0.7550\n",
      "Epoch 18/150\n",
      "80000/80000 [==============================] - 5s 63us/step - loss: 0.9010 - mean_absolute_error: 0.7535 - val_loss: 0.9083 - val_mean_absolute_error: 0.7546\n",
      "Epoch 19/150\n",
      "48000/80000 [=================>............] - ETA: 1s - loss: 0.8996 - mean_absolute_error: 0.753180000/80000 [==============================] - 5s 61us/step - loss: 0.9003 - mean_absolute_error: 0.7535 - val_loss: 0.9064 - val_mean_absolute_error: 0.7512\n",
      "Epoch 20/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.9018 - mean_absolute_error: 0.7538 - val_loss: 0.9071 - val_mean_absolute_error: 0.7554\n",
      "Epoch 21/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.8977 - mean_absolute_error: 0.7534 - val_loss: 0.9056 - val_mean_absolute_error: 0.7523\n",
      "Epoch 22/150\n",
      "51040/80000 [==================>...........] - ETA: 1s - loss: 0.8990 - mean_absolute_error: 0.753180000/80000 [==============================] - 5s 61us/step - loss: 0.8971 - mean_absolute_error: 0.7523 - val_loss: 0.9021 - val_mean_absolute_error: 0.7485\n",
      "Epoch 23/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.8989 - mean_absolute_error: 0.7529 - val_loss: 0.8988 - val_mean_absolute_error: 0.7478\n",
      "Epoch 24/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8978 - mean_absolute_error: 0.7520 - val_loss: 0.9045 - val_mean_absolute_error: 0.7528\n",
      "Epoch 25/150\n",
      "52704/80000 [==================>...........] - ETA: 1s - loss: 0.8942 - mean_absolute_error: 0.750280000/80000 [==============================] - 5s 60us/step - loss: 0.8962 - mean_absolute_error: 0.7516 - val_loss: 0.9021 - val_mean_absolute_error: 0.7521\n",
      "Epoch 26/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8960 - mean_absolute_error: 0.7512 - val_loss: 0.9042 - val_mean_absolute_error: 0.7531\n",
      "Epoch 27/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.8945 - mean_absolute_error: 0.7517 - val_loss: 0.9059 - val_mean_absolute_error: 0.7560\n",
      "Epoch 28/150\n",
      "52512/80000 [==================>...........] - ETA: 1s - loss: 0.8867 - mean_absolute_error: 0.746780000/80000 [==============================] - 5s 61us/step - loss: 0.8934 - mean_absolute_error: 0.7498 - val_loss: 0.8998 - val_mean_absolute_error: 0.7506\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 1.3589 - mean_absolute_error: 0.9589 - val_loss: 1.2723 - val_mean_absolute_error: 0.9427\n",
      "Epoch 2/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 1.1538 - mean_absolute_error: 0.8837 - val_loss: 1.1163 - val_mean_absolute_error: 0.8611\n",
      "Epoch 3/150\n",
      "51072/80000 [==================>...........] - ETA: 1s - loss: 1.0717 - mean_absolute_error: 0.838480000/80000 [==============================] - 4s 55us/step - loss: 1.0650 - mean_absolute_error: 0.8344 - val_loss: 1.0315 - val_mean_absolute_error: 0.8149\n",
      "Epoch 4/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 1.0208 - mean_absolute_error: 0.8128 - val_loss: 0.9911 - val_mean_absolute_error: 0.7944\n",
      "Epoch 5/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.9976 - mean_absolute_error: 0.8013 - val_loss: 0.9759 - val_mean_absolute_error: 0.7896\n",
      "Epoch 6/150\n",
      "66432/80000 [=======================>......] - ETA: 0s - loss: 0.9896 - mean_absolute_error: 0.798680000/80000 [==============================] - 4s 55us/step - loss: 0.9870 - mean_absolute_error: 0.7970 - val_loss: 0.9662 - val_mean_absolute_error: 0.7861\n",
      "Epoch 7/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.9771 - mean_absolute_error: 0.7924 - val_loss: 0.9577 - val_mean_absolute_error: 0.7847\n",
      "Epoch 8/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.9634 - mean_absolute_error: 0.7867 - val_loss: 0.9424 - val_mean_absolute_error: 0.7753\n",
      "Epoch 9/150\n",
      "68896/80000 [========================>.....] - ETA: 0s - loss: 0.9583 - mean_absolute_error: 0.784280000/80000 [==============================] - 4s 56us/step - loss: 0.9567 - mean_absolute_error: 0.7832 - val_loss: 0.9357 - val_mean_absolute_error: 0.7696\n",
      "Epoch 10/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.9488 - mean_absolute_error: 0.7792 - val_loss: 0.9320 - val_mean_absolute_error: 0.7694\n",
      "Epoch 11/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.9478 - mean_absolute_error: 0.7790 - val_loss: 0.9306 - val_mean_absolute_error: 0.7682\n",
      "Epoch 12/150\n",
      "70784/80000 [=========================>....] - ETA: 0s - loss: 0.9419 - mean_absolute_error: 0.776580000/80000 [==============================] - 4s 55us/step - loss: 0.9409 - mean_absolute_error: 0.7763 - val_loss: 0.9211 - val_mean_absolute_error: 0.7604\n",
      "Epoch 13/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.9369 - mean_absolute_error: 0.7737 - val_loss: 0.9285 - val_mean_absolute_error: 0.7654\n",
      "Epoch 14/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.9353 - mean_absolute_error: 0.7734 - val_loss: 0.9238 - val_mean_absolute_error: 0.7659\n",
      "Epoch 15/150\n",
      "71712/80000 [=========================>....] - ETA: 0s - loss: 0.9312 - mean_absolute_error: 0.771880000/80000 [==============================] - 4s 55us/step - loss: 0.9342 - mean_absolute_error: 0.7726 - val_loss: 0.9237 - val_mean_absolute_error: 0.7653\n",
      "Epoch 16/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.9281 - mean_absolute_error: 0.7694 - val_loss: 0.9166 - val_mean_absolute_error: 0.7643\n",
      "Epoch 17/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.9275 - mean_absolute_error: 0.7694 - val_loss: 0.9164 - val_mean_absolute_error: 0.7627\n",
      "Epoch 18/150\n",
      "73280/80000 [==========================>...] - ETA: 0s - loss: 0.9272 - mean_absolute_error: 0.770180000/80000 [==============================] - 4s 55us/step - loss: 0.9259 - mean_absolute_error: 0.7697 - val_loss: 0.9204 - val_mean_absolute_error: 0.7695\n",
      "Epoch 19/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.9274 - mean_absolute_error: 0.7696 - val_loss: 0.9125 - val_mean_absolute_error: 0.7611\n",
      "Epoch 20/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.9255 - mean_absolute_error: 0.7689 - val_loss: 0.9092 - val_mean_absolute_error: 0.7602\n",
      "Epoch 21/150\n",
      "71488/80000 [=========================>....] - ETA: 0s - loss: 0.9253 - mean_absolute_error: 0.768480000/80000 [==============================] - 4s 56us/step - loss: 0.9226 - mean_absolute_error: 0.7673 - val_loss: 0.9209 - val_mean_absolute_error: 0.7678\n",
      "Epoch 22/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.9204 - mean_absolute_error: 0.7669 - val_loss: 0.9072 - val_mean_absolute_error: 0.7599\n",
      "Epoch 23/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.9202 - mean_absolute_error: 0.7667 - val_loss: 0.9061 - val_mean_absolute_error: 0.7586\n",
      "Epoch 24/150\n",
      "70336/80000 [=========================>....] - ETA: 0s - loss: 0.9178 - mean_absolute_error: 0.765380000/80000 [==============================] - 4s 56us/step - loss: 0.9187 - mean_absolute_error: 0.7660 - val_loss: 0.9104 - val_mean_absolute_error: 0.7594\n",
      "Epoch 25/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.9173 - mean_absolute_error: 0.7649 - val_loss: 0.9114 - val_mean_absolute_error: 0.7589\n",
      "Epoch 26/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.9171 - mean_absolute_error: 0.7648 - val_loss: 0.9080 - val_mean_absolute_error: 0.7593\n",
      "Epoch 27/150\n",
      "70336/80000 [=========================>....] - ETA: 0s - loss: 0.9143 - mean_absolute_error: 0.763480000/80000 [==============================] - 4s 56us/step - loss: 0.9163 - mean_absolute_error: 0.7643 - val_loss: 0.9099 - val_mean_absolute_error: 0.7583\n",
      "Epoch 28/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.9145 - mean_absolute_error: 0.7640 - val_loss: 0.9151 - val_mean_absolute_error: 0.7592\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 5s 67us/step - loss: 2.2967 - mean_absolute_error: 1.1919 - val_loss: 1.0788 - val_mean_absolute_error: 0.8536\n",
      "Epoch 2/150\n",
      "46496/80000 [================>.............] - ETA: 1s - loss: 1.3031 - mean_absolute_error: 0.920180000/80000 [==============================] - 5s 61us/step - loss: 1.2498 - mean_absolute_error: 0.9011 - val_loss: 0.9868 - val_mean_absolute_error: 0.8029\n",
      "Epoch 3/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 1.0563 - mean_absolute_error: 0.8257 - val_loss: 0.9714 - val_mean_absolute_error: 0.7977\n",
      "Epoch 4/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.9796 - mean_absolute_error: 0.7932 - val_loss: 0.9407 - val_mean_absolute_error: 0.7719\n",
      "Epoch 5/150\n",
      "47392/80000 [================>.............] - ETA: 1s - loss: 0.9435 - mean_absolute_error: 0.776280000/80000 [==============================] - 5s 64us/step - loss: 0.9464 - mean_absolute_error: 0.7771 - val_loss: 0.9335 - val_mean_absolute_error: 0.7695\n",
      "Epoch 6/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.9341 - mean_absolute_error: 0.7715 - val_loss: 0.9309 - val_mean_absolute_error: 0.7692\n",
      "Epoch 7/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.9247 - mean_absolute_error: 0.7652 - val_loss: 0.9281 - val_mean_absolute_error: 0.7656\n",
      "Epoch 8/150\n",
      "48000/80000 [=================>............] - ETA: 1s - loss: 0.9145 - mean_absolute_error: 0.762180000/80000 [==============================] - 5s 62us/step - loss: 0.9221 - mean_absolute_error: 0.7652 - val_loss: 0.9225 - val_mean_absolute_error: 0.7640\n",
      "Epoch 9/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.9178 - mean_absolute_error: 0.7621 - val_loss: 0.9244 - val_mean_absolute_error: 0.7662\n",
      "Epoch 10/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.9140 - mean_absolute_error: 0.7608 - val_loss: 0.9194 - val_mean_absolute_error: 0.7601\n",
      "Epoch 11/150\n",
      "50592/80000 [=================>............] - ETA: 1s - loss: 0.9015 - mean_absolute_error: 0.755080000/80000 [==============================] - 5s 62us/step - loss: 0.9137 - mean_absolute_error: 0.7605 - val_loss: 0.9164 - val_mean_absolute_error: 0.7599\n",
      "Epoch 12/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.9121 - mean_absolute_error: 0.7587 - val_loss: 0.9170 - val_mean_absolute_error: 0.7636\n",
      "Epoch 13/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.9080 - mean_absolute_error: 0.7573 - val_loss: 0.9140 - val_mean_absolute_error: 0.7565\n",
      "Epoch 14/150\n",
      "50112/80000 [=================>............] - ETA: 1s - loss: 0.9001 - mean_absolute_error: 0.754080000/80000 [==============================] - 5s 62us/step - loss: 0.9056 - mean_absolute_error: 0.7557 - val_loss: 0.9156 - val_mean_absolute_error: 0.7587\n",
      "Epoch 15/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.9014 - mean_absolute_error: 0.7542 - val_loss: 0.9140 - val_mean_absolute_error: 0.7587\n",
      "Epoch 16/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8982 - mean_absolute_error: 0.7529 - val_loss: 0.9078 - val_mean_absolute_error: 0.7519\n",
      "Epoch 17/150\n",
      "51584/80000 [==================>...........] - ETA: 1s - loss: 0.8996 - mean_absolute_error: 0.752580000/80000 [==============================] - 5s 61us/step - loss: 0.8963 - mean_absolute_error: 0.7513 - val_loss: 0.9083 - val_mean_absolute_error: 0.7553\n",
      "Epoch 18/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.8978 - mean_absolute_error: 0.7525 - val_loss: 0.9062 - val_mean_absolute_error: 0.7547\n",
      "Epoch 19/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.8967 - mean_absolute_error: 0.7522 - val_loss: 0.9029 - val_mean_absolute_error: 0.7522\n",
      "Epoch 20/150\n",
      "50816/80000 [==================>...........] - ETA: 1s - loss: 0.8956 - mean_absolute_error: 0.750980000/80000 [==============================] - 5s 60us/step - loss: 0.8962 - mean_absolute_error: 0.7517 - val_loss: 0.9021 - val_mean_absolute_error: 0.7510\n",
      "Epoch 21/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8931 - mean_absolute_error: 0.7500 - val_loss: 0.9027 - val_mean_absolute_error: 0.7498\n",
      "Epoch 22/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.8951 - mean_absolute_error: 0.7512 - val_loss: 0.9044 - val_mean_absolute_error: 0.7558\n",
      "Epoch 23/150\n",
      "52864/80000 [==================>...........] - ETA: 1s - loss: 0.8926 - mean_absolute_error: 0.749580000/80000 [==============================] - 5s 60us/step - loss: 0.8948 - mean_absolute_error: 0.7510 - val_loss: 0.9035 - val_mean_absolute_error: 0.7530\n",
      "Epoch 24/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.8900 - mean_absolute_error: 0.7484 - val_loss: 0.9046 - val_mean_absolute_error: 0.7547\n",
      "Epoch 25/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8907 - mean_absolute_error: 0.7488 - val_loss: 0.9012 - val_mean_absolute_error: 0.7509\n",
      "Epoch 26/150\n",
      "52736/80000 [==================>...........] - ETA: 1s - loss: 0.8924 - mean_absolute_error: 0.749980000/80000 [==============================] - 5s 61us/step - loss: 0.8869 - mean_absolute_error: 0.7476 - val_loss: 0.9019 - val_mean_absolute_error: 0.7520\n",
      "Epoch 27/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8901 - mean_absolute_error: 0.7488 - val_loss: 0.8998 - val_mean_absolute_error: 0.7511\n",
      "Epoch 28/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8954 - mean_absolute_error: 0.7509 - val_loss: 0.9029 - val_mean_absolute_error: 0.7502\n",
      "Epoch 29/150\n",
      "53376/80000 [===================>..........] - ETA: 1s - loss: 0.8866 - mean_absolute_error: 0.746380000/80000 [==============================] - 5s 61us/step - loss: 0.8886 - mean_absolute_error: 0.7481 - val_loss: 0.9001 - val_mean_absolute_error: 0.7484\n",
      "Epoch 30/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.8899 - mean_absolute_error: 0.7493 - val_loss: 0.8987 - val_mean_absolute_error: 0.7498\n",
      "Epoch 31/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.8863 - mean_absolute_error: 0.7479 - val_loss: 0.8997 - val_mean_absolute_error: 0.7499\n",
      "Epoch 32/150\n",
      "51488/80000 [==================>...........] - ETA: 1s - loss: 0.8828 - mean_absolute_error: 0.746780000/80000 [==============================] - 5s 62us/step - loss: 0.8867 - mean_absolute_error: 0.7481 - val_loss: 0.9011 - val_mean_absolute_error: 0.7517\n",
      "Epoch 33/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.8877 - mean_absolute_error: 0.7479 - val_loss: 0.8971 - val_mean_absolute_error: 0.7475\n",
      "Epoch 34/150\n",
      "80000/80000 [==============================] - 5s 63us/step - loss: 0.8863 - mean_absolute_error: 0.7474 - val_loss: 0.9001 - val_mean_absolute_error: 0.7506\n",
      "Epoch 35/150\n",
      "48160/80000 [=================>............] - ETA: 1s - loss: 0.8816 - mean_absolute_error: 0.745880000/80000 [==============================] - 5s 62us/step - loss: 0.8872 - mean_absolute_error: 0.7480 - val_loss: 0.8957 - val_mean_absolute_error: 0.7491\n",
      "Epoch 36/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.8861 - mean_absolute_error: 0.7469 - val_loss: 0.8990 - val_mean_absolute_error: 0.7480\n",
      "Epoch 37/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8900 - mean_absolute_error: 0.7492 - val_loss: 0.9008 - val_mean_absolute_error: 0.7539\n",
      "Epoch 38/150\n",
      "49632/80000 [=================>............] - ETA: 1s - loss: 0.8872 - mean_absolute_error: 0.749080000/80000 [==============================] - 5s 61us/step - loss: 0.8891 - mean_absolute_error: 0.7492 - val_loss: 0.9038 - val_mean_absolute_error: 0.7552\n",
      "Epoch 39/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8875 - mean_absolute_error: 0.7473 - val_loss: 0.8984 - val_mean_absolute_error: 0.7503\n",
      "Epoch 40/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8839 - mean_absolute_error: 0.7463 - val_loss: 0.8971 - val_mean_absolute_error: 0.7484\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "53440/80000 [===================>..........] - ETA: 1s - loss: 1.4194 - mean_absolute_error: 0.971680000/80000 [==============================] - 5s 62us/step - loss: 1.3511 - mean_absolute_error: 0.9539 - val_loss: 1.2525 - val_mean_absolute_error: 0.9337\n",
      "Epoch 2/150\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 1.1243 - mean_absolute_error: 0.8683 - val_loss: 1.0825 - val_mean_absolute_error: 0.8474\n",
      "Epoch 3/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 1.0414 - mean_absolute_error: 0.8220 - val_loss: 1.0045 - val_mean_absolute_error: 0.8053\n",
      "Epoch 4/150\n",
      "68096/80000 [========================>.....] - ETA: 0s - loss: 1.0005 - mean_absolute_error: 0.801080000/80000 [==============================] - 4s 56us/step - loss: 0.9980 - mean_absolute_error: 0.7997 - val_loss: 0.9738 - val_mean_absolute_error: 0.7841\n",
      "Epoch 5/150\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 0.9739 - mean_absolute_error: 0.7893 - val_loss: 0.9529 - val_mean_absolute_error: 0.7758\n",
      "Epoch 6/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.9524 - mean_absolute_error: 0.7797 - val_loss: 0.9474 - val_mean_absolute_error: 0.7775\n",
      "Epoch 7/150\n",
      "68928/80000 [========================>.....] - ETA: 0s - loss: 0.9378 - mean_absolute_error: 0.772680000/80000 [==============================] - 5s 57us/step - loss: 0.9415 - mean_absolute_error: 0.7749 - val_loss: 0.9297 - val_mean_absolute_error: 0.7682\n",
      "Epoch 8/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.9319 - mean_absolute_error: 0.7697 - val_loss: 0.9266 - val_mean_absolute_error: 0.7641\n",
      "Epoch 9/150\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 0.9273 - mean_absolute_error: 0.7680 - val_loss: 0.9213 - val_mean_absolute_error: 0.7619\n",
      "Epoch 10/150\n",
      "69760/80000 [=========================>....] - ETA: 0s - loss: 0.9183 - mean_absolute_error: 0.763280000/80000 [==============================] - 4s 56us/step - loss: 0.9203 - mean_absolute_error: 0.7642 - val_loss: 0.9159 - val_mean_absolute_error: 0.7547\n",
      "Epoch 11/150\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 0.9157 - mean_absolute_error: 0.7626 - val_loss: 0.9196 - val_mean_absolute_error: 0.7562\n",
      "Epoch 12/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.9124 - mean_absolute_error: 0.7613 - val_loss: 0.9184 - val_mean_absolute_error: 0.7573\n",
      "Epoch 13/150\n",
      "67072/80000 [========================>.....] - ETA: 0s - loss: 0.9049 - mean_absolute_error: 0.757480000/80000 [==============================] - 4s 56us/step - loss: 0.9078 - mean_absolute_error: 0.7593 - val_loss: 0.9110 - val_mean_absolute_error: 0.7530\n",
      "Epoch 14/150\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 0.9079 - mean_absolute_error: 0.7589 - val_loss: 0.9111 - val_mean_absolute_error: 0.7552\n",
      "Epoch 15/150\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 0.9007 - mean_absolute_error: 0.7568 - val_loss: 0.9061 - val_mean_absolute_error: 0.7514\n",
      "Epoch 16/150\n",
      "67328/80000 [========================>.....] - ETA: 0s - loss: 0.9024 - mean_absolute_error: 0.757180000/80000 [==============================] - 5s 56us/step - loss: 0.9034 - mean_absolute_error: 0.7573 - val_loss: 0.9005 - val_mean_absolute_error: 0.7518\n",
      "Epoch 17/150\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 0.8985 - mean_absolute_error: 0.7536 - val_loss: 0.9027 - val_mean_absolute_error: 0.7532\n",
      "Epoch 18/150\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 0.8957 - mean_absolute_error: 0.7533 - val_loss: 0.9000 - val_mean_absolute_error: 0.7493\n",
      "Epoch 19/150\n",
      "66880/80000 [========================>.....] - ETA: 0s - loss: 0.8960 - mean_absolute_error: 0.753580000/80000 [==============================] - 5s 56us/step - loss: 0.8980 - mean_absolute_error: 0.7542 - val_loss: 0.9045 - val_mean_absolute_error: 0.7503\n",
      "Epoch 20/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.8943 - mean_absolute_error: 0.7523 - val_loss: 0.9028 - val_mean_absolute_error: 0.7554\n",
      "Epoch 21/150\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 0.8932 - mean_absolute_error: 0.7530 - val_loss: 0.9026 - val_mean_absolute_error: 0.7478\n",
      "Epoch 22/150\n",
      "67712/80000 [========================>.....] - ETA: 0s - loss: 0.8946 - mean_absolute_error: 0.753380000/80000 [==============================] - 5s 57us/step - loss: 0.8923 - mean_absolute_error: 0.7520 - val_loss: 0.9032 - val_mean_absolute_error: 0.7511\n",
      "Epoch 23/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.8904 - mean_absolute_error: 0.7506 - val_loss: 0.8985 - val_mean_absolute_error: 0.7493\n",
      "Epoch 24/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.8893 - mean_absolute_error: 0.7509 - val_loss: 0.8938 - val_mean_absolute_error: 0.7490\n",
      "Epoch 25/150\n",
      "67744/80000 [========================>.....] - ETA: 0s - loss: 0.8881 - mean_absolute_error: 0.749080000/80000 [==============================] - 4s 56us/step - loss: 0.8889 - mean_absolute_error: 0.7496 - val_loss: 0.8962 - val_mean_absolute_error: 0.7499\n",
      "Epoch 26/150\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 0.8905 - mean_absolute_error: 0.7512 - val_loss: 0.8983 - val_mean_absolute_error: 0.7528\n",
      "Epoch 27/150\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.8862 - mean_absolute_error: 0.7497 - val_loss: 0.8996 - val_mean_absolute_error: 0.7491\n",
      "Epoch 28/150\n",
      "70112/80000 [=========================>....] - ETA: 0s - loss: 0.8850 - mean_absolute_error: 0.749480000/80000 [==============================] - 4s 56us/step - loss: 0.8841 - mean_absolute_error: 0.7490 - val_loss: 0.8980 - val_mean_absolute_error: 0.7443\n",
      "Epoch 29/150\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.8817 - mean_absolute_error: 0.7460 - val_loss: 0.8990 - val_mean_absolute_error: 0.7511\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 6s 73us/step - loss: 2.1884 - mean_absolute_error: 1.1789 - val_loss: 1.0866 - val_mean_absolute_error: 0.8598\n",
      "Epoch 2/150\n",
      "40256/80000 [==============>...............] - ETA: 2s - loss: 1.3626 - mean_absolute_error: 0.942380000/80000 [==============================] - 5s 65us/step - loss: 1.2735 - mean_absolute_error: 0.9107 - val_loss: 0.9831 - val_mean_absolute_error: 0.8036\n",
      "Epoch 3/150\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 1.0419 - mean_absolute_error: 0.8219 - val_loss: 0.9625 - val_mean_absolute_error: 0.7952\n",
      "Epoch 4/150\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.9716 - mean_absolute_error: 0.7897 - val_loss: 0.9358 - val_mean_absolute_error: 0.7682\n",
      "Epoch 5/150\n",
      "40160/80000 [==============>...............] - ETA: 2s - loss: 0.9427 - mean_absolute_error: 0.774380000/80000 [==============================] - 5s 66us/step - loss: 0.9518 - mean_absolute_error: 0.7785 - val_loss: 0.9365 - val_mean_absolute_error: 0.7713\n",
      "Epoch 6/150\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.9417 - mean_absolute_error: 0.7735 - val_loss: 0.9281 - val_mean_absolute_error: 0.7649\n",
      "Epoch 7/150\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.9334 - mean_absolute_error: 0.7695 - val_loss: 0.9212 - val_mean_absolute_error: 0.7663\n",
      "Epoch 8/150\n",
      "38880/80000 [=============>................] - ETA: 2s - loss: 0.9272 - mean_absolute_error: 0.766680000/80000 [==============================] - 5s 66us/step - loss: 0.9290 - mean_absolute_error: 0.7675 - val_loss: 0.9180 - val_mean_absolute_error: 0.7624\n",
      "Epoch 9/150\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 0.9231 - mean_absolute_error: 0.7644 - val_loss: 0.9109 - val_mean_absolute_error: 0.7512\n",
      "Epoch 10/150\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.9200 - mean_absolute_error: 0.7627 - val_loss: 0.9149 - val_mean_absolute_error: 0.7609\n",
      "Epoch 11/150\n",
      "39872/80000 [=============>................] - ETA: 2s - loss: 0.9196 - mean_absolute_error: 0.761980000/80000 [==============================] - 5s 65us/step - loss: 0.9177 - mean_absolute_error: 0.7619 - val_loss: 0.9139 - val_mean_absolute_error: 0.7586\n",
      "Epoch 12/150\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.9183 - mean_absolute_error: 0.7620 - val_loss: 0.9138 - val_mean_absolute_error: 0.7559\n",
      "Epoch 13/150\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 0.9110 - mean_absolute_error: 0.7576 - val_loss: 0.9067 - val_mean_absolute_error: 0.7504\n",
      "Epoch 14/150\n",
      "39616/80000 [=============>................] - ETA: 2s - loss: 0.9053 - mean_absolute_error: 0.754980000/80000 [==============================] - 5s 65us/step - loss: 0.9083 - mean_absolute_error: 0.7568 - val_loss: 0.9072 - val_mean_absolute_error: 0.7534\n",
      "Epoch 15/150\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.9105 - mean_absolute_error: 0.7564 - val_loss: 0.9072 - val_mean_absolute_error: 0.7530\n",
      "Epoch 16/150\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 0.9027 - mean_absolute_error: 0.7540 - val_loss: 0.9006 - val_mean_absolute_error: 0.7482\n",
      "Epoch 17/150\n",
      "38528/80000 [=============>................] - ETA: 2s - loss: 0.9070 - mean_absolute_error: 0.754980000/80000 [==============================] - 5s 65us/step - loss: 0.9034 - mean_absolute_error: 0.7538 - val_loss: 0.9060 - val_mean_absolute_error: 0.7478\n",
      "Epoch 18/150\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.9005 - mean_absolute_error: 0.7529 - val_loss: 0.9104 - val_mean_absolute_error: 0.7499\n",
      "Epoch 19/150\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.9027 - mean_absolute_error: 0.7534 - val_loss: 0.9022 - val_mean_absolute_error: 0.7520\n",
      "Epoch 20/150\n",
      "39520/80000 [=============>................] - ETA: 2s - loss: 0.9025 - mean_absolute_error: 0.754080000/80000 [==============================] - 5s 64us/step - loss: 0.8988 - mean_absolute_error: 0.7523 - val_loss: 0.9012 - val_mean_absolute_error: 0.7511\n",
      "Epoch 21/150\n",
      "80000/80000 [==============================] - 5s 64us/step - loss: 0.8979 - mean_absolute_error: 0.7515 - val_loss: 0.9008 - val_mean_absolute_error: 0.7473\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 5s 68us/step - loss: 1.3904 - mean_absolute_error: 0.9718 - val_loss: 1.3305 - val_mean_absolute_error: 0.9685\n",
      "Epoch 2/150\n",
      "39424/80000 [=============>................] - ETA: 2s - loss: 1.2525 - mean_absolute_error: 0.939780000/80000 [==============================] - 5s 59us/step - loss: 1.2508 - mean_absolute_error: 0.9387 - val_loss: 1.3279 - val_mean_absolute_error: 0.9664\n",
      "Epoch 3/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 1.2389 - mean_absolute_error: 0.9328 - val_loss: 1.2705 - val_mean_absolute_error: 0.9469\n",
      "Epoch 4/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 1.1080 - mean_absolute_error: 0.8565 - val_loss: 1.0377 - val_mean_absolute_error: 0.8296\n",
      "Epoch 5/150\n",
      "52640/80000 [==================>...........] - ETA: 1s - loss: 1.0129 - mean_absolute_error: 0.809480000/80000 [==============================] - 5s 59us/step - loss: 1.0115 - mean_absolute_error: 0.8084 - val_loss: 0.9815 - val_mean_absolute_error: 0.7915\n",
      "Epoch 6/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9854 - mean_absolute_error: 0.7963 - val_loss: 0.9590 - val_mean_absolute_error: 0.7891\n",
      "Epoch 7/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9694 - mean_absolute_error: 0.7888 - val_loss: 0.9466 - val_mean_absolute_error: 0.7773\n",
      "Epoch 8/150\n",
      "56640/80000 [====================>.........] - ETA: 1s - loss: 0.9484 - mean_absolute_error: 0.779180000/80000 [==============================] - 5s 60us/step - loss: 0.9546 - mean_absolute_error: 0.7819 - val_loss: 0.9410 - val_mean_absolute_error: 0.7712\n",
      "Epoch 9/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9459 - mean_absolute_error: 0.7778 - val_loss: 0.9321 - val_mean_absolute_error: 0.7724\n",
      "Epoch 10/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9437 - mean_absolute_error: 0.7760 - val_loss: 0.9283 - val_mean_absolute_error: 0.7627\n",
      "Epoch 11/150\n",
      "55648/80000 [===================>..........] - ETA: 1s - loss: 0.9360 - mean_absolute_error: 0.772780000/80000 [==============================] - 5s 59us/step - loss: 0.9398 - mean_absolute_error: 0.7739 - val_loss: 0.9337 - val_mean_absolute_error: 0.7690\n",
      "Epoch 12/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9342 - mean_absolute_error: 0.7706 - val_loss: 0.9402 - val_mean_absolute_error: 0.7622\n",
      "Epoch 13/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9324 - mean_absolute_error: 0.7694 - val_loss: 0.9182 - val_mean_absolute_error: 0.7554\n",
      "Epoch 14/150\n",
      "55648/80000 [===================>..........] - ETA: 1s - loss: 0.9204 - mean_absolute_error: 0.763080000/80000 [==============================] - 5s 61us/step - loss: 0.9244 - mean_absolute_error: 0.7657 - val_loss: 0.9186 - val_mean_absolute_error: 0.7599\n",
      "Epoch 15/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9200 - mean_absolute_error: 0.7638 - val_loss: 0.9089 - val_mean_absolute_error: 0.7529\n",
      "Epoch 16/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9185 - mean_absolute_error: 0.7633 - val_loss: 0.9208 - val_mean_absolute_error: 0.7564\n",
      "Epoch 17/150\n",
      "55072/80000 [===================>..........] - ETA: 1s - loss: 0.9154 - mean_absolute_error: 0.761480000/80000 [==============================] - 5s 60us/step - loss: 0.9130 - mean_absolute_error: 0.7606 - val_loss: 0.9053 - val_mean_absolute_error: 0.7549\n",
      "Epoch 18/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9095 - mean_absolute_error: 0.7596 - val_loss: 0.9031 - val_mean_absolute_error: 0.7516\n",
      "Epoch 19/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9054 - mean_absolute_error: 0.7573 - val_loss: 0.9043 - val_mean_absolute_error: 0.7555\n",
      "Epoch 20/150\n",
      "55840/80000 [===================>..........] - ETA: 1s - loss: 0.9080 - mean_absolute_error: 0.758980000/80000 [==============================] - 5s 60us/step - loss: 0.9052 - mean_absolute_error: 0.7576 - val_loss: 0.9029 - val_mean_absolute_error: 0.7507\n",
      "Epoch 21/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9043 - mean_absolute_error: 0.7577 - val_loss: 0.9100 - val_mean_absolute_error: 0.7582\n",
      "Epoch 22/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8983 - mean_absolute_error: 0.7544 - val_loss: 0.8961 - val_mean_absolute_error: 0.7501\n",
      "Epoch 23/150\n",
      "54624/80000 [===================>..........] - ETA: 1s - loss: 0.8944 - mean_absolute_error: 0.751680000/80000 [==============================] - 5s 60us/step - loss: 0.8963 - mean_absolute_error: 0.7529 - val_loss: 0.8991 - val_mean_absolute_error: 0.7482\n",
      "Epoch 24/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8979 - mean_absolute_error: 0.7544 - val_loss: 0.8968 - val_mean_absolute_error: 0.7501\n",
      "Epoch 25/150\n",
      "80000/80000 [==============================] - 5s 59us/step - loss: 0.8940 - mean_absolute_error: 0.7528 - val_loss: 0.8964 - val_mean_absolute_error: 0.7460\n",
      "Epoch 26/150\n",
      "55872/80000 [===================>..........] - ETA: 1s - loss: 0.8882 - mean_absolute_error: 0.750280000/80000 [==============================] - 5s 60us/step - loss: 0.8960 - mean_absolute_error: 0.7537 - val_loss: 0.8962 - val_mean_absolute_error: 0.7498\n",
      "Epoch 27/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8917 - mean_absolute_error: 0.7512 - val_loss: 0.8967 - val_mean_absolute_error: 0.7495\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 6s 76us/step - loss: 2.4941 - mean_absolute_error: 1.2587 - val_loss: 1.1260 - val_mean_absolute_error: 0.8780\n",
      "Epoch 2/150\n",
      "32832/80000 [===========>..................] - ETA: 2s - loss: 1.4168 - mean_absolute_error: 0.964980000/80000 [==============================] - 5s 66us/step - loss: 1.2652 - mean_absolute_error: 0.9083 - val_loss: 0.9985 - val_mean_absolute_error: 0.8170\n",
      "Epoch 3/150\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 1.0081 - mean_absolute_error: 0.8082 - val_loss: 0.9441 - val_mean_absolute_error: 0.7765\n",
      "Epoch 4/150\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 0.9546 - mean_absolute_error: 0.7826 - val_loss: 0.9372 - val_mean_absolute_error: 0.7673\n",
      "Epoch 5/150\n",
      "36256/80000 [============>.................] - ETA: 2s - loss: 0.9306 - mean_absolute_error: 0.770180000/80000 [==============================] - 5s 66us/step - loss: 0.9339 - mean_absolute_error: 0.7715 - val_loss: 0.9302 - val_mean_absolute_error: 0.7687\n",
      "Epoch 6/150\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 0.9264 - mean_absolute_error: 0.7668 - val_loss: 0.9243 - val_mean_absolute_error: 0.7622\n",
      "Epoch 7/150\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 0.9181 - mean_absolute_error: 0.7616 - val_loss: 0.9138 - val_mean_absolute_error: 0.7562\n",
      "Epoch 8/150\n",
      "38368/80000 [=============>................] - ETA: 2s - loss: 0.9193 - mean_absolute_error: 0.761780000/80000 [==============================] - 5s 65us/step - loss: 0.9111 - mean_absolute_error: 0.7577 - val_loss: 0.9118 - val_mean_absolute_error: 0.7543\n",
      "Epoch 9/150\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.9070 - mean_absolute_error: 0.7565 - val_loss: 0.9099 - val_mean_absolute_error: 0.7553\n",
      "Epoch 10/150\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 0.9017 - mean_absolute_error: 0.7545 - val_loss: 0.9094 - val_mean_absolute_error: 0.7508\n",
      "Epoch 11/150\n",
      "38560/80000 [=============>................] - ETA: 2s - loss: 0.9005 - mean_absolute_error: 0.752480000/80000 [==============================] - 5s 66us/step - loss: 0.8997 - mean_absolute_error: 0.7525 - val_loss: 0.8987 - val_mean_absolute_error: 0.7465\n",
      "Epoch 12/150\n",
      "80000/80000 [==============================] - 5s 67us/step - loss: 0.8960 - mean_absolute_error: 0.7508 - val_loss: 0.9032 - val_mean_absolute_error: 0.7534\n",
      "Epoch 13/150\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 0.8934 - mean_absolute_error: 0.7496 - val_loss: 0.9024 - val_mean_absolute_error: 0.7521\n",
      "Epoch 14/150\n",
      "37216/80000 [============>.................] - ETA: 2s - loss: 0.8907 - mean_absolute_error: 0.745580000/80000 [==============================] - 5s 66us/step - loss: 0.8919 - mean_absolute_error: 0.7477 - val_loss: 0.9000 - val_mean_absolute_error: 0.7471\n",
      "Epoch 15/150\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 0.8857 - mean_absolute_error: 0.7460 - val_loss: 0.9027 - val_mean_absolute_error: 0.7536\n",
      "Epoch 16/150\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 0.8888 - mean_absolute_error: 0.7475 - val_loss: 0.9005 - val_mean_absolute_error: 0.7521\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "37792/80000 [=============>................] - ETA: 2s - loss: 1.5063 - mean_absolute_error: 0.996180000/80000 [==============================] - 6s 69us/step - loss: 1.3618 - mean_absolute_error: 0.9590 - val_loss: 1.2574 - val_mean_absolute_error: 0.9423\n",
      "Epoch 2/150\n",
      "80000/80000 [==============================] - 5s 59us/step - loss: 1.1155 - mean_absolute_error: 0.8567 - val_loss: 1.0707 - val_mean_absolute_error: 0.8326\n",
      "Epoch 3/150\n",
      "80000/80000 [==============================] - 5s 59us/step - loss: 1.0421 - mean_absolute_error: 0.8136 - val_loss: 1.0310 - val_mean_absolute_error: 0.8127\n",
      "Epoch 4/150\n",
      "55200/80000 [===================>..........] - ETA: 1s - loss: 1.0068 - mean_absolute_error: 0.799680000/80000 [==============================] - 5s 59us/step - loss: 1.0068 - mean_absolute_error: 0.8004 - val_loss: 0.9948 - val_mean_absolute_error: 0.7924\n",
      "Epoch 5/150\n",
      "80000/80000 [==============================] - 5s 59us/step - loss: 0.9844 - mean_absolute_error: 0.7919 - val_loss: 0.9600 - val_mean_absolute_error: 0.7784\n",
      "Epoch 6/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9678 - mean_absolute_error: 0.7855 - val_loss: 0.9585 - val_mean_absolute_error: 0.7832\n",
      "Epoch 7/150\n",
      "55552/80000 [===================>..........] - ETA: 1s - loss: 0.9621 - mean_absolute_error: 0.782680000/80000 [==============================] - 5s 60us/step - loss: 0.9603 - mean_absolute_error: 0.7819 - val_loss: 0.9450 - val_mean_absolute_error: 0.7703\n",
      "Epoch 8/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9520 - mean_absolute_error: 0.7780 - val_loss: 0.9444 - val_mean_absolute_error: 0.7663\n",
      "Epoch 9/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9479 - mean_absolute_error: 0.7754 - val_loss: 0.9353 - val_mean_absolute_error: 0.7640\n",
      "Epoch 10/150\n",
      "56576/80000 [====================>.........] - ETA: 1s - loss: 0.9470 - mean_absolute_error: 0.775680000/80000 [==============================] - 5s 60us/step - loss: 0.9450 - mean_absolute_error: 0.7751 - val_loss: 0.9380 - val_mean_absolute_error: 0.7676\n",
      "Epoch 11/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9395 - mean_absolute_error: 0.7730 - val_loss: 0.9361 - val_mean_absolute_error: 0.7634\n",
      "Epoch 12/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9398 - mean_absolute_error: 0.7714 - val_loss: 0.9273 - val_mean_absolute_error: 0.7625\n",
      "Epoch 13/150\n",
      "55136/80000 [===================>..........] - ETA: 1s - loss: 0.9277 - mean_absolute_error: 0.767480000/80000 [==============================] - 5s 61us/step - loss: 0.9306 - mean_absolute_error: 0.7683 - val_loss: 0.9215 - val_mean_absolute_error: 0.7619\n",
      "Epoch 14/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9281 - mean_absolute_error: 0.7670 - val_loss: 0.9168 - val_mean_absolute_error: 0.7585\n",
      "Epoch 15/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.9298 - mean_absolute_error: 0.7675 - val_loss: 0.9259 - val_mean_absolute_error: 0.7616\n",
      "Epoch 16/150\n",
      "55136/80000 [===================>..........] - ETA: 1s - loss: 0.9265 - mean_absolute_error: 0.765180000/80000 [==============================] - 5s 60us/step - loss: 0.9258 - mean_absolute_error: 0.7658 - val_loss: 0.9234 - val_mean_absolute_error: 0.7611\n",
      "Epoch 17/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9280 - mean_absolute_error: 0.7664 - val_loss: 0.9190 - val_mean_absolute_error: 0.7554\n",
      "Epoch 18/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.9229 - mean_absolute_error: 0.7642 - val_loss: 0.9108 - val_mean_absolute_error: 0.7532\n",
      "Epoch 19/150\n",
      "53888/80000 [===================>..........] - ETA: 1s - loss: 0.9201 - mean_absolute_error: 0.762380000/80000 [==============================] - 5s 61us/step - loss: 0.9217 - mean_absolute_error: 0.7636 - val_loss: 0.9134 - val_mean_absolute_error: 0.7548\n",
      "Epoch 20/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.9189 - mean_absolute_error: 0.7627 - val_loss: 0.9133 - val_mean_absolute_error: 0.7620\n",
      "Epoch 21/150\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.9196 - mean_absolute_error: 0.7632 - val_loss: 0.9120 - val_mean_absolute_error: 0.7533\n",
      "Epoch 22/150\n",
      "50880/80000 [==================>...........] - ETA: 1s - loss: 0.9170 - mean_absolute_error: 0.760680000/80000 [==============================] - 5s 62us/step - loss: 0.9157 - mean_absolute_error: 0.7618 - val_loss: 0.9094 - val_mean_absolute_error: 0.7562\n",
      "Epoch 23/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9145 - mean_absolute_error: 0.7610 - val_loss: 0.9092 - val_mean_absolute_error: 0.7531\n",
      "Epoch 24/150\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.9133 - mean_absolute_error: 0.7605 - val_loss: 0.9115 - val_mean_absolute_error: 0.7521\n",
      "Epoch 25/150\n",
      "53280/80000 [==================>...........] - ETA: 1s - loss: 0.9146 - mean_absolute_error: 0.760980000/80000 [==============================] - 5s 60us/step - loss: 0.9158 - mean_absolute_error: 0.7614 - val_loss: 0.9138 - val_mean_absolute_error: 0.7582\n",
      "Epoch 26/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9139 - mean_absolute_error: 0.7604 - val_loss: 0.9059 - val_mean_absolute_error: 0.7545\n",
      "Epoch 27/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9128 - mean_absolute_error: 0.7607 - val_loss: 0.9114 - val_mean_absolute_error: 0.7585\n",
      "Epoch 28/150\n",
      "55680/80000 [===================>..........] - ETA: 1s - loss: 0.9115 - mean_absolute_error: 0.759480000/80000 [==============================] - 5s 60us/step - loss: 0.9113 - mean_absolute_error: 0.7597 - val_loss: 0.9094 - val_mean_absolute_error: 0.7572\n",
      "Epoch 29/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9091 - mean_absolute_error: 0.7588 - val_loss: 0.9075 - val_mean_absolute_error: 0.7560\n",
      "Epoch 30/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9064 - mean_absolute_error: 0.7578 - val_loss: 0.9085 - val_mean_absolute_error: 0.7512\n",
      "Epoch 31/150\n",
      "54464/80000 [===================>..........] - ETA: 1s - loss: 0.9086 - mean_absolute_error: 0.756780000/80000 [==============================] - 5s 60us/step - loss: 0.9076 - mean_absolute_error: 0.7569 - val_loss: 0.9057 - val_mean_absolute_error: 0.7525\n",
      "Epoch 32/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9087 - mean_absolute_error: 0.7585 - val_loss: 0.9077 - val_mean_absolute_error: 0.7633\n",
      "Epoch 33/150\n",
      "80000/80000 [==============================] - 5s 59us/step - loss: 0.9072 - mean_absolute_error: 0.7574 - val_loss: 0.9058 - val_mean_absolute_error: 0.7522\n",
      "Epoch 34/150\n",
      "56864/80000 [====================>.........] - ETA: 1s - loss: 0.9057 - mean_absolute_error: 0.756180000/80000 [==============================] - 5s 59us/step - loss: 0.9079 - mean_absolute_error: 0.7576 - val_loss: 0.9143 - val_mean_absolute_error: 0.7599\n",
      "Epoch 35/150\n",
      "80000/80000 [==============================] - 5s 59us/step - loss: 0.9051 - mean_absolute_error: 0.7564 - val_loss: 0.9068 - val_mean_absolute_error: 0.7598\n",
      "Epoch 36/150\n",
      "80000/80000 [==============================] - 5s 59us/step - loss: 0.9047 - mean_absolute_error: 0.7567 - val_loss: 0.9046 - val_mean_absolute_error: 0.7505\n",
      "Epoch 37/150\n",
      "58016/80000 [====================>.........] - ETA: 1s - loss: 0.9010 - mean_absolute_error: 0.756180000/80000 [==============================] - 5s 59us/step - loss: 0.9014 - mean_absolute_error: 0.7554 - val_loss: 0.8926 - val_mean_absolute_error: 0.7497\n",
      "Epoch 38/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9026 - mean_absolute_error: 0.7558 - val_loss: 0.9087 - val_mean_absolute_error: 0.7509\n",
      "Epoch 39/150\n",
      "80000/80000 [==============================] - 5s 59us/step - loss: 0.9009 - mean_absolute_error: 0.7549 - val_loss: 0.9027 - val_mean_absolute_error: 0.7500\n",
      "Epoch 40/150\n",
      "57024/80000 [====================>.........] - ETA: 1s - loss: 0.8931 - mean_absolute_error: 0.752380000/80000 [==============================] - 5s 59us/step - loss: 0.8990 - mean_absolute_error: 0.7540 - val_loss: 0.9034 - val_mean_absolute_error: 0.7531\n",
      "Epoch 41/150\n",
      "80000/80000 [==============================] - 5s 59us/step - loss: 0.8999 - mean_absolute_error: 0.7536 - val_loss: 0.9013 - val_mean_absolute_error: 0.7523\n",
      "Epoch 42/150\n",
      "80000/80000 [==============================] - 5s 59us/step - loss: 0.9025 - mean_absolute_error: 0.7557 - val_loss: 0.8969 - val_mean_absolute_error: 0.7492\n"
     ]
    }
   ],
   "source": [
    "K_LATENT = 20\n",
    "do = 0.5\n",
    "num_of_nuerons = [15, 20]\n",
    "num_of_layers = [1, 3]\n",
    "optimizers = [(Adamax(), 'Adamax'), (SGD(), 'SGD')]\n",
    "results = []\n",
    "for layers in num_of_layers:\n",
    "  for nuerons in num_of_nuerons:\n",
    "    for opt, opt_name in optimizers:\n",
    "      NCF_model = get_ncf_model(max_userid, max_movieid, K_LATENT, nuerons, do, layers)\n",
    "      NCF_model.compile(loss='mse', optimizer=opt, metrics=['mae'])\n",
    "      callbacks_ncf = [EarlyStopping('val_loss', patience=5)]\n",
    "      NCF_history = NCF_model.fit([Users, Movies], Ratings, epochs=150, validation_split=.2, verbose=1, callbacks=callbacks_ncf, batch_size = 32)\n",
    "      results.append((layers, nuerons, opt_name, NCF_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1532810528256,
     "user": {
      "displayName": "Ran Tsur",
      "photoUrl": "//lh3.googleusercontent.com/-pkQ4mq31yyM/AAAAAAAAAAI/AAAAAAAAABg/OJrKb1aE-5Q/s50-c-k-no/photo.jpg",
      "userId": "106754954225433138332"
     },
     "user_tz": -180
    },
    "id": "N040QuEsP96-",
    "outputId": "ba200686-2684-48c0-a621-ae9ec908c106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Const parameters: Loss Function - MSE\n",
      "Using 1 hidden layers sized 15 , Adamax as optimizer in 28 epochs: Average MAE is 0.7850146589381355 Min MAE is 0.749778125333786\n",
      "Using 1 hidden layers sized 15 , SGD as optimizer in 28 epochs: Average MAE is 0.7884379261136056 Min MAE is 0.7639994487762451\n",
      "Using 1 hidden layers sized 20 , Adamax as optimizer in 40 epochs: Average MAE is 0.7708266069939732 Min MAE is 0.7462981087684631\n",
      "Using 1 hidden layers sized 20 , SGD as optimizer in 29 epochs: Average MAE is 0.7728053828054462 Min MAE is 0.7460360916137695\n",
      "Using 3 hidden layers sized 15 , Adamax as optimizer in 21 epochs: Average MAE is 0.7919087006943565 Min MAE is 0.7515310255050659\n",
      "Using 3 hidden layers sized 15 , SGD as optimizer in 27 epochs: Average MAE is 0.7906686696158516 Min MAE is 0.7512444159984588\n",
      "Using 3 hidden layers sized 20 , Adamax as optimizer in 16 epochs: Average MAE is 0.8012737548299134 Min MAE is 0.7460245637416839\n",
      "Using 3 hidden layers sized 20 , SGD as optimizer in 42 epochs: Average MAE is 0.772993517169782 Min MAE is 0.7535679046154022\n"
     ]
    }
   ],
   "source": [
    "print(\"Const parameters: Loss Function - MSE\")\n",
    "for num_of_layers, num_of_nuerons, optimizer, history in results:\n",
    "  avg = np.mean(history.history['mean_absolute_error'])\n",
    "  epochs = len(history.history['mean_absolute_error'])\n",
    "  minimum = min(history.history['mean_absolute_error'])\n",
    "  print(\"Using\", num_of_layers, \"hidden layers sized\", num_of_nuerons, \",\" , optimizer, \"as optimizer in\", epochs, \"epochs: Average MAE is\", avg,\"Min MAE is\", minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UqmX1105mMWo"
   },
   "source": [
    "The minimal MAE (0.7404) for Neural Collaborative Filtering was achieved using 3 hidden layers sized 20, \"Adamax\" as optimizer and took 31 epochs to converge. Comparing to GMF, the minimal MAE of NCF is higher but its average MAE is lower. the best method the smallest MAE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ludOelb2pTKx"
   },
   "source": [
    "## Ex 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LbQOMz97ph6r"
   },
   "source": [
    "**Section A**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "be1pv5R4plem"
   },
   "source": [
    "Categorical feature (movie category) requires more effort in order to trasform than binary (gender) or continuos feature (age).\n",
    "Hence, we decided to add to the model with the best results so far (GMF), the features of age and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "l4gwbDWHpY_x"
   },
   "outputs": [],
   "source": [
    "u_cols = ['userid', 'age', 'gender']\n",
    "users_df = pd.read_csv(USERS_DATA_FILE_PATH, delimiter='|', encoding='latin-1', names=u_cols, usecols=[0, 1, 2])\n",
    "users_df['gender'].replace('M', 0, inplace=True)\n",
    "users_df['gender'].replace('F', 1, inplace=True)\n",
    "joined_with_users_df = pd.merge(joined_df, users_df,on='userid')\n",
    "Gender = joined_with_users_df['gender'].values\n",
    "Age = joined_with_users_df['age'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "31LkcFMIse-n"
   },
   "outputs": [],
   "source": [
    "def get_gmf_model_gen(num_users, num_items, latent_dim, do, max_age):\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "    gender_input = Input(shape=(1,), dtype='float32', name = 'gender_input')\n",
    "    age_input = Input(shape=(1,), dtype='float32', name = 'age_input')\n",
    "\n",
    "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding', input_length=1)\n",
    "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding', input_length=1)\n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(MF_Embedding_User(user_input))\n",
    "    item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
    "    \n",
    "    # Element-wise product of user and item embeddings\n",
    "    hidden1 = Multiply()([user_latent, item_latent])\n",
    "    conc = Concatenate()([hidden1, gender_input, age_input])\n",
    "    drop = Dropout(do)(conc)\n",
    "    prediction = Dense(1, activation='relu', kernel_initializer='lecun_uniform', name = 'prediction')(conc)\n",
    "    \n",
    "    model = Model(input=[user_input, item_input,gender_input, age_input], output=prediction)\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xQzwMrp9HZ1"
   },
   "source": [
    "**Section B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1006
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 132424,
     "status": "ok",
     "timestamp": 1532810703146,
     "user": {
      "displayName": "Ran Tsur",
      "photoUrl": "//lh3.googleusercontent.com/-pkQ4mq31yyM/AAAAAAAAAAI/AAAAAAAAABg/OJrKb1aE-5Q/s50-c-k-no/photo.jpg",
      "userId": "106754954225433138332"
     },
     "user_tz": -180
    },
    "id": "ozxgKgIbsi91",
    "outputId": "b95f804f-7a78-4af7-eeba-57a3bb2c3a80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"pr...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 6s 74us/step - loss: 13.7004 - mean_absolute_error: 3.5284 - val_loss: 13.8335 - val_mean_absolute_error: 3.5359\n",
      "Epoch 2/150\n",
      "80000/80000 [==============================] - 5s 58us/step - loss: 13.7004 - mean_absolute_error: 3.5284 - val_loss: 13.8335 - val_mean_absolute_error: 3.5359\n",
      "Epoch 3/150\n",
      "80000/80000 [==============================] - 5s 58us/step - loss: 13.7004 - mean_absolute_error: 3.5284 - val_loss: 13.8335 - val_mean_absolute_error: 3.5359\n",
      "Epoch 4/150\n",
      "21216/80000 [======>.......................] - ETA: 3s - loss: 13.7179 - mean_absolute_error: 3.530680000/80000 [==============================] - 5s 59us/step - loss: 13.7004 - mean_absolute_error: 3.5284 - val_loss: 13.8335 - val_mean_absolute_error: 3.5359\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 6s 73us/step - loss: 13.7004 - mean_absolute_error: 3.5284 - val_loss: 13.8335 - val_mean_absolute_error: 3.5359\n",
      "Epoch 2/150\n",
      "80000/80000 [==============================] - 5s 63us/step - loss: 13.7004 - mean_absolute_error: 3.5284 - val_loss: 13.8335 - val_mean_absolute_error: 3.5359\n",
      "Epoch 3/150\n",
      "24672/80000 [========>.....................] - ETA: 3s - loss: 13.8288 - mean_absolute_error: 3.548580000/80000 [==============================] - 5s 64us/step - loss: 13.7004 - mean_absolute_error: 3.5284 - val_loss: 13.8335 - val_mean_absolute_error: 3.5359\n",
      "Epoch 4/150\n",
      "80000/80000 [==============================] - 5s 64us/step - loss: 13.7004 - mean_absolute_error: 3.5284 - val_loss: 13.8335 - val_mean_absolute_error: 3.5359\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 6s 70us/step - loss: 2.0762 - mean_absolute_error: 1.1775 - val_loss: 1.7841 - val_mean_absolute_error: 1.0791\n",
      "Epoch 2/150\n",
      "36608/80000 [============>.................] - ETA: 2s - loss: 1.5600 - mean_absolute_error: 1.018080000/80000 [==============================] - 5s 60us/step - loss: 1.4692 - mean_absolute_error: 0.9886 - val_loss: 1.4032 - val_mean_absolute_error: 0.9611\n",
      "Epoch 3/150\n",
      "80000/80000 [==============================] - 5s 59us/step - loss: 1.2009 - mean_absolute_error: 0.9052 - val_loss: 1.2221 - val_mean_absolute_error: 0.9121\n",
      "Epoch 4/150\n",
      "80000/80000 [==============================] - 5s 59us/step - loss: 1.0553 - mean_absolute_error: 0.8356 - val_loss: 1.1579 - val_mean_absolute_error: 0.8651\n",
      "Epoch 5/150\n",
      "54464/80000 [===================>..........] - ETA: 1s - loss: 0.9837 - mean_absolute_error: 0.795980000/80000 [==============================] - 5s 59us/step - loss: 0.9767 - mean_absolute_error: 0.7921 - val_loss: 1.0975 - val_mean_absolute_error: 0.8356\n",
      "Epoch 6/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.9083 - mean_absolute_error: 0.7563 - val_loss: 1.0330 - val_mean_absolute_error: 0.8128\n",
      "Epoch 7/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.8489 - mean_absolute_error: 0.7272 - val_loss: 0.9991 - val_mean_absolute_error: 0.7941\n",
      "Epoch 8/150\n",
      "55776/80000 [===================>..........] - ETA: 1s - loss: 0.8027 - mean_absolute_error: 0.704180000/80000 [==============================] - 5s 60us/step - loss: 0.8004 - mean_absolute_error: 0.7036 - val_loss: 0.9788 - val_mean_absolute_error: 0.7872\n",
      "Epoch 9/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.7597 - mean_absolute_error: 0.6833 - val_loss: 0.9617 - val_mean_absolute_error: 0.7756\n",
      "Epoch 10/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.7238 - mean_absolute_error: 0.6653 - val_loss: 0.9558 - val_mean_absolute_error: 0.7690\n",
      "Epoch 11/150\n",
      "54720/80000 [===================>..........] - ETA: 1s - loss: 0.6920 - mean_absolute_error: 0.648680000/80000 [==============================] - 5s 60us/step - loss: 0.6922 - mean_absolute_error: 0.6485 - val_loss: 0.9487 - val_mean_absolute_error: 0.7692\n",
      "Epoch 12/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.6644 - mean_absolute_error: 0.6338 - val_loss: 0.9591 - val_mean_absolute_error: 0.7659\n",
      "Epoch 13/150\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.6390 - mean_absolute_error: 0.6197 - val_loss: 0.9518 - val_mean_absolute_error: 0.7708\n",
      "Epoch 14/150\n",
      "55552/80000 [===================>..........] - ETA: 1s - loss: 0.6129 - mean_absolute_error: 0.604880000/80000 [==============================] - 5s 59us/step - loss: 0.6160 - mean_absolute_error: 0.6070 - val_loss: 0.9566 - val_mean_absolute_error: 0.7660\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/150\n",
      "80000/80000 [==============================] - 6s 76us/step - loss: 13.7004 - mean_absolute_error: 3.5284 - val_loss: 13.8335 - val_mean_absolute_error: 3.5359\n",
      "Epoch 2/150\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 13.7004 - mean_absolute_error: 3.5284 - val_loss: 13.8335 - val_mean_absolute_error: 3.5359\n",
      "Epoch 3/150\n",
      "27040/80000 [=========>....................] - ETA: 3s - loss: 13.6969 - mean_absolute_error: 3.530480000/80000 [==============================] - 5s 64us/step - loss: 13.7004 - mean_absolute_error: 3.5284 - val_loss: 13.8335 - val_mean_absolute_error: 3.5359\n",
      "Epoch 4/150\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 13.7004 - mean_absolute_error: 3.5284 - val_loss: 13.8335 - val_mean_absolute_error: 3.5359\n"
     ]
    }
   ],
   "source": [
    "k_latents = [20, 30]\n",
    "drop_out = [0.3, 0.5]\n",
    "GMF_results_features_add = []\n",
    "max_age = max(Age)\n",
    "for do in drop_out:\n",
    "  for k in k_latents:\n",
    "    GMF_model = get_gmf_model_gen(max_userid,max_movieid,k,do,max_age)\n",
    "    GMF_model.compile(loss='mse',optimizer=Adamax(),metrics=['mae'])\n",
    "    callbacks = [EarlyStopping('val_loss', patience=3)]\n",
    "    GMF_results_features_add_history = GMF_model.fit([Users, Movies, Gender, Age], Ratings, epochs=150, validation_split=.2, verbose=1, callbacks=callbacks, batch_size = 32)\n",
    "    GMF_results_features_add.append((k, do, GMF_results_features_add_history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2fV1wPz_zRXz"
   },
   "source": [
    "**Ex 3 Section C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 693,
     "status": "ok",
     "timestamp": 1532810808987,
     "user": {
      "displayName": "Ran Tsur",
      "photoUrl": "//lh3.googleusercontent.com/-pkQ4mq31yyM/AAAAAAAAAAI/AAAAAAAAABg/OJrKb1aE-5Q/s50-c-k-no/photo.jpg",
      "userId": "106754954225433138332"
     },
     "user_tz": -180
    },
    "id": "HTKc2-M2xukz",
    "outputId": "b88a20d8-7416-4a0a-eda4-582973403fbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop out of  0.3 and  20  latent dimension in 4 epochs => Average MAE: 3.52835 , Min MAE 3.52835\n",
      "drop out of  0.3 and  30  latent dimension in 4 epochs => Average MAE: 3.52835 , Min MAE 3.52835\n",
      "drop out of  0.5 and  20  latent dimension in 14 epochs => Average MAE: 0.767402311807871 , Min MAE 0.6069800953626633\n",
      "drop out of  0.5 and  30  latent dimension in 4 epochs => Average MAE: 3.52835 , Min MAE 3.52835\n"
     ]
    }
   ],
   "source": [
    "for k, drop_out, history in GMF_results_features_add:\n",
    "  avg = np.mean(history.history['mean_absolute_error'])\n",
    "  epochs = len(history.history['mean_absolute_error'])\n",
    "  minimum = min(history.history['mean_absolute_error'])\n",
    "  print(\"drop out of \", drop_out,\"and \",  k, \" latent dimension in\", epochs, \"epochs =>\",  \"Average MAE:\", avg, \", Min MAE\",minimum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ZSDsnOlzY-F"
   },
   "source": [
    "**Ex 3 Section D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgypEFyOzbNX"
   },
   "source": [
    "We add to the GMF model the features: age and gender, and then we got min MAE - 0.551 - which improved the model's results.\n",
    "The reason for the relatively small running time of the model is the high MAE in the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Zzu8jm7zyut"
   },
   "source": [
    "**Ex 3 Section E**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDYXE1N20_EC"
   },
   "source": [
    "The Results Are:\n",
    "\n",
    "1. Simple Matrix Factorization - min. MAE: 0.6166\n",
    "2. Generalized Matrix Factorization - min. MAE: 0.5793\n",
    "3. Neural Collaborative Filtering - min. MAE: 0.739\n",
    "\n",
    "So far, the best results are for the Generalized Matrix Factorization model.\n",
    "\n",
    "We decided to add the features of \"age\" and \"gender\" to the GMF model in order the improved the MAE.\n",
    "\n",
    "We can see, according to Section C that the addition of the features improved the results - from 0.5793 to 0.5551.\n",
    "\n",
    "We would recommend GMF with the features adding as the model with the best results in order to predict movies ratings."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Ass3-ran&mor.ipynb",
   "provenance": [
    {
     "file_id": "1_ctWj6DREsiYqZ2ZLIgetwq2UegHe8kn",
     "timestamp": 1530120708390
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
